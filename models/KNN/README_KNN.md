# üéØ K-NN com weights='distance' - Modelo Leak-Free

## üìã Vis√£o Geral

Modelo **K-Nearest Neighbors (K-NN)** otimizado para predi√ß√£o de convers√£o de usu√°rios em aplicativo de transporte p√∫blico (Cittamobi).

- **Algoritmo**: K-Nearest Neighbors
- **Melhor K**: 31
- **Weights**: 'distance' (vizinhos mais pr√≥ximos t√™m mais peso)
- **ROC-AUC**: 0.7492
- **F1-Macro**: 0.6464
- **Status**: ‚úÖ Leak-Free (sem vazamento de dados)

---

## üö® Preven√ß√£o de Data Leakage

### ‚ùå Problema Identificado
Features como `user_conversion_rate` e `stop_conversion_rate` eram calculadas usando o pr√≥prio target, causando **vazamento de dados** e ROC-AUC artificialmente alto (>98%).

### ‚úÖ Solu√ß√£o Implementada
1. **Expanding Windows**: Para cada evento em tempo T, usar apenas dados hist√≥ricos < T
2. **TimeSeriesSplit**: Valida√ß√£o temporal que respeita ordem cronol√≥gica
3. **Features Hist√≥ricas**: Substitui√ß√£o por agrega√ß√µes baseadas apenas no passado
4. **Normaliza√ß√£o**: StandardScaler essencial para K-NN funcionar corretamente

---

## üìä M√©tricas de Performance

| M√©trica | Valor |
|---------|-------|
| **ROC-AUC** | **0.7492** |
| Accuracy | 0.8968 |
| Precision | 0.4209 |
| Recall | 0.2980 |
| F1-Score | 0.3489 |
| F1-Macro | 0.6464 |
| Threshold | 0.30 |

### Matriz de Confus√£o

```
                 Predito
                 0        1
Real  0       9,621      421
      1         721      306
```

- **True Negatives**: 9,621
- **False Positives**: 421
- **False Negatives**: 721
- **True Positives**: 306

---

## üîç Compara√ß√£o de Valores de K

| K | ROC-AUC | F1-Macro | Tempo (s) |
|---|---------|----------|----------|
| 31 üèÜ | 0.7492 | 0.6464 | 0.5 |
| 21 | 0.7414 | 0.6415 | 0.5 |
| 15 | 0.7305 | 0.6421 | 0.5 |
| 11 | 0.7166 | 0.6340 | 0.5 |
|  7 | 0.6926 | 0.6264 | 0.5 |
|  5 | 0.6742 | 0.6170 | 0.6 |
|  3 | 0.6474 | 0.5868 | 0.6 |

### Insights sobre K
- **K muito pequeno** (3-5): Sens√≠vel a ru√≠do, overfitting
- **K moderado** (31): **Melhor balan√ßo** entre vi√©s e vari√¢ncia
- **K muito grande** (>31): Underfitting, perde padr√µes locais

---

## üîß Configura√ß√£o T√©cnica

### Par√¢metros K-NN
```python
KNeighborsClassifier(
    n_neighbors=31,
    weights='distance',  # Vizinhos pr√≥ximos t√™m mais peso
    algorithm='auto',    # Escolhe melhor algoritmo (ball_tree/kd_tree/brute)
    metric='minkowski',  # Dist√¢ncia Euclidiana
    p=2,                 # p=2 para Euclidiana
    n_jobs=-1            # Usa todos os cores do CPU
)
```

### Pipeline de Pr√©-processamento
```python
Pipeline([
    ('scaler', StandardScaler()),  # Normaliza√ß√£o ESSENCIAL!
    ('knn', KNeighborsClassifier(...))
])
```

‚ö†Ô∏è **IMPORTANTE**: StandardScaler √© **obrigat√≥rio** para K-NN! Sem normaliza√ß√£o, features com escalas diferentes dominam o c√°lculo de dist√¢ncia.

---

## üìà Top 10 Features Mais Importantes

*(Baseado em vari√¢ncia ap√≥s normaliza√ß√£o)*

| Rank | Feature | Vari√¢ncia |
|------|---------|----------|
| 1 | `dist_deviation_hist` | 1.0000 |
| 2 | `dist_ratio_hist` | 1.0000 |
| 3 | `user_avg_hour_hist` | 1.0000 |
| 4 | `Unnamed: 0` | 1.0000 |
| 5 | `stop_headway_mean` | 1.0000 |
| 6 | `stop_dist_std` | 1.0000 |
| 7 | `stop_dist_mean` | 1.0000 |
| 8 | `day_of_month_cos` | 1.0000 |
| 9 | `dist_x_peak` | 1.0000 |
| 10 | `week_cos` | 1.0000 |

---

## üìä Compara√ß√£o com Outros Modelos

| Modelo | ROC-AUC | Observa√ß√µes |
|--------|---------|-------------|
| **V6 CatBoost** | **86.69%** | üèÜ Melhor modelo geral |
| **V5 LightGBM** | **86.42%** | Segundo melhor |
| **K-NN (K=31)** | **74.92%** | Mais simples e interpret√°vel |

### üí° Quando Usar K-NN?

‚úÖ **Vantagens**:
- Simples e f√°cil de entender
- N√£o faz suposi√ß√µes sobre distribui√ß√£o dos dados
- Funciona bem com dados n√£o-lineares
- Interpretabilidade: decis√µes baseadas em vizinhos similares

‚ùå **Desvantagens**:
- Performance inferior a gradient boosting em dados tabulares
- Sens√≠vel a features irrelevantes e alta dimensionalidade
- Computacionalmente caro em produ√ß√£o (precisa calcular dist√¢ncias)
- Requer normaliza√ß√£o e pr√©-processamento cuidadoso

---

## üóÇÔ∏è Estrutura de Arquivos

```
KNN/
‚îú‚îÄ‚îÄ knn_leak_free.py              # Script principal
‚îú‚îÄ‚îÄ README_KNN.md                  # Esta documenta√ß√£o
‚îú‚îÄ‚îÄ visualizations/
‚îÇ   ‚îú‚îÄ‚îÄ k_comparison.png           # Compara√ß√£o de valores K
‚îÇ   ‚îú‚îÄ‚îÄ roc_curve_knn.png          # Curva ROC
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix_knn.png   # Matriz de confus√£o
‚îÇ   ‚îî‚îÄ‚îÄ feature_variance_knn.png   # Import√¢ncia features
‚îî‚îÄ‚îÄ reports/
    ‚îú‚îÄ‚îÄ knn_leak_free_report.txt   # Relat√≥rio detalhado
    ‚îî‚îÄ‚îÄ knn_k_comparison.csv        # Dados compara√ß√£o K
```

---

## üöÄ Como Usar

### 1. Executar o Modelo
```bash
cd KNN
python knn_leak_free.py
```

### 2. Ver Resultados
- **Visualiza√ß√µes**: `visualizations/*.png`
- **Relat√≥rio T√©cnico**: `reports/knn_leak_free_report.txt`
- **Dados Compara√ß√£o**: `reports/knn_k_comparison.csv`

### 3. Ajustar Par√¢metros
No c√≥digo `knn_leak_free.py`, linha ~344:
```python
k_values = [3, 5, 7, 11, 15, 21, 31]  # Adicionar mais valores
```

---

## ‚öôÔ∏è Requisitos T√©cnicos

```
Python >= 3.9
scikit-learn >= 1.0
pandas >= 1.3
numpy >= 1.21
matplotlib >= 3.4
seaborn >= 0.11
google-cloud-bigquery >= 3.0
```

---

## üìù Metodologia de Desenvolvimento

### 1. Prepara√ß√£o Temporal dos Dados
- Ordena√ß√£o cronol√≥gica por `event_timestamp`
- Features temporais e c√≠clicas (sin/cos)
- Per√≠odo: 3 meses de dados

### 2. Expanding Windows (Leak-Free)
Para cada evento em tempo T:
```python
# ‚úÖ CORRETO: Usa apenas hist√≥rico < T
hist_data = df.iloc[:i]  # Dados anteriores
user_hist_conversion_rate = hist_data[target].mean()

# ‚ùå ERRADO: Usa todos os dados (inclui futuro)
user_conversion_rate = df.groupby('user')[target].mean()
```

### 3. Valida√ß√£o Temporal
- **TimeSeriesSplit** com 3 folds
- Treino: 75% dos dados (temporalmente anteriores)
- Teste: 25% dos dados (temporalmente posteriores)

### 4. Otimiza√ß√£o de Hiperpar√¢metros
- Grid search manual em valores de K
- Threshold otimizado para maximizar F1-Macro
- StandardScaler aplicado em todas as features

---

## üéì Conceitos Importantes

### K-Nearest Neighbors (K-NN)
Algoritmo de aprendizado supervisionado que classifica novos pontos baseado nos **K vizinhos mais pr√≥ximos** no espa√ßo de features.

### weights='distance'
Vizinhos mais pr√≥ximos t√™m **maior peso** na decis√£o:
```
peso = 1 / dist√¢ncia
```
Resultado: Pontos muito pr√≥ximos influenciam mais a predi√ß√£o.

### StandardScaler
Normaliza features para m√©dia=0 e desvio=1:
```
X_scaled = (X - mean) / std
```
**Essencial para K-NN**: Sem normaliza√ß√£o, features com valores grandes dominam dist√¢ncias.

### Expanding Windows
T√©cnica anti-vazamento para s√©ries temporais:
- Cada predi√ß√£o usa **apenas dados do passado**
- Simula exatamente o ambiente de produ√ß√£o
- Previne que modelo "veja o futuro"

---

## üèÜ Resultados e Conclus√µes

### Performance Alcan√ßada
- **ROC-AUC**: 0.7492 (real√≠stico para o problema)
- **F1-Macro**: 0.6464 (bom balan√ßo entre classes)
- **Tempo de treino**: 0.5s (r√°pido)

### Compara√ß√£o com Gradient Boosting
K-NN teve performance **inferior** a CatBoost/LightGBM:
- CatBoost: 86.69% vs K-NN: 74.92%
- **Motivo**: K-NN sofre com alta dimensionalidade (58 features)
- **Motivo**: K-NN √© sens√≠vel a features irrelevantes

### Recomenda√ß√£o Final
- ‚úÖ **Para Produ√ß√£o**: CatBoost ou LightGBM (melhor performance)
- ‚úÖ **Para Interpretabilidade**: K-NN (decis√µes transparentes)
- ‚úÖ **Para Baseline**: K-NN (r√°pido de implementar)

---

## üìö Refer√™ncias

- [Scikit-learn K-NN Documentation](https://scikit-learn.org/stable/modules/neighbors.html)
- [K-NN Theory and Practice](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)
- [StandardScaler Guide](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)
- [TimeSeriesSplit for Temporal Validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)

---

## üë®‚Äçüíª Autor e Contato

**Projeto**: Cittamobi ML - Predi√ß√£o de Convers√£o de Usu√°rios
**Data**: Novembro 2025
**Status**: ‚úÖ Produ√ß√£o-Ready (Leak-Free)

---

## üìÑ Licen√ßa

Este projeto √© parte do portf√≥lio de Machine Learning Cittamobi.
