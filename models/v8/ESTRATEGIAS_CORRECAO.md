# ğŸ¯ ESTRATÃ‰GIAS PARA CORRIGIR SUBESTIMAÃ‡ÃƒO DE ALTA CONVERSÃƒO

## ğŸ“Š Problema Identificado

**Sintomas:**
- Modelo prevÃª ~21% para TODAS as paradas
- Dataset possui paradas com 20% atÃ© **98.5%** de conversÃ£o real
- Modelo nÃ£o captura a variaÃ§Ã£o: erro mÃ©dio de 19.1%
- 100% das prediÃ§Ãµes ficam na categoria "MÃ©dia" (10-30%)
- 57 paradas com conversÃ£o 50-100% â†’ modelo prevÃª 0 nessa faixa

**Causa Raiz:**
O modelo estÃ¡ aprendendo a **mÃ©dia geral** (~20%) mas nÃ£o as **caracterÃ­sticas especÃ­ficas** que diferenciam paradas de alta conversÃ£o.

---

## ğŸ”§ SOLUÃ‡Ã•ES PROPOSTAS

### 1ï¸âƒ£ **ESTRATÃ‰GIA 1: Adicionar Features GeogrÃ¡ficas EspecÃ­ficas** â­ MAIS IMPORTANTE

**Problema:** Paradas com alta conversÃ£o podem estar em locais especÃ­ficos (terminais, Ã¡reas centrais, etc.)

**SoluÃ§Ã£o:**
```python
# A. Agregar conversÃ£o POR PARADA (nÃ£o sÃ³ mÃ©dia geral)
stop_conversion_rate = df.groupby('gtfs_stop_id')['target'].mean()
df['stop_historical_conversion'] = df['gtfs_stop_id'].map(stop_conversion_rate)

# B. Densidade de paradas (Ã¡reas centrais tÃªm mais paradas)
from sklearn.neighbors import NearestNeighbors
coords = df[['stop_lat_event', 'stop_lon_event']].values
nn = NearestNeighbors(n_neighbors=10)
nn.fit(coords)
distances, _ = nn.kneighbors(coords)
df['stop_density'] = 1 / distances[:, 1:].mean(axis=1)  # Paradas prÃ³ximas

# C. DistÃ¢ncia ao centro (CBD - Central Business District)
centro_sp = (-23.550520, -46.633308)  # PraÃ§a da SÃ©
df['dist_to_cbd'] = haversine(df['stop_lat_event'], df['stop_lon_event'], 
                               centro_sp[0], centro_sp[1])

# D. RegiÃ£o/Cluster de paradas
from sklearn.cluster import DBSCAN
clustering = DBSCAN(eps=0.01, min_samples=5)
df['stop_cluster'] = clustering.fit_predict(coords)
```

**Por que funciona:** Paradas de alta conversÃ£o geralmente estÃ£o em locais especÃ­ficos (terminais, Ã¡reas comerciais). Essa feature ensina o modelo a reconhecer esses lugares.

---

### 2ï¸âƒ£ **ESTRATÃ‰GIA 2: Balanceamento por Binning** â­ CRÃTICO

**Problema:** Dataset desbalanceado: 92.5% classe 0, 7.5% classe 1

**SoluÃ§Ã£o:**
```python
# Converter em problema multi-classe
df['target_binned'] = pd.cut(df['conversion_rate'], 
                              bins=[0, 0.1, 0.3, 0.5, 1.0],
                              labels=[0, 1, 2, 3])  # Baixa, MÃ©dia, Alta, Muito Alta

# Usar scale_pos_weight mais agressivo
scale_weight = len(df[df['target']==0]) / len(df[df['target']==1])  # ~12.3

lgb_params = {
    'scale_pos_weight': scale_weight * 1.5,  # Aumentar peso das conversÃµes
    'class_weight': 'balanced'
}
```

---

### 3ï¸âƒ£ **ESTRATÃ‰GIA 3: Focal Loss** (XGBoost Custom)

**Problema:** Cross-entropy padrÃ£o trata todos os exemplos igualmente

**SoluÃ§Ã£o:**
```python
# Focal Loss: penaliza mais erros em exemplos "difÃ­ceis" (alta conversÃ£o)
def focal_loss(y_pred, dtrain, alpha=0.25, gamma=2.0):
    y_true = dtrain.get_label()
    p = 1 / (1 + np.exp(-y_pred))
    
    # Focal loss formula
    loss = -alpha * (1 - p)**gamma * y_true * np.log(p + 1e-8) \
           - (1 - alpha) * p**gamma * (1 - y_true) * np.log(1 - p + 1e-8)
    
    grad = alpha * (gamma * (1 - p)**(gamma - 1) * y_true * np.log(p) + 
                    (1 - p)**gamma * y_true / p) - \
           (1 - alpha) * (gamma * p**(gamma - 1) * (1 - y_true) * np.log(1 - p) + 
                          p**gamma * (1 - y_true) / (1 - p))
    
    hess = np.ones_like(grad)  # AproximaÃ§Ã£o
    return grad, hess

xgb_model = xgb.train(params, dtrain, obj=focal_loss)
```

---

### 4ï¸âƒ£ **ESTRATÃ‰GIA 4: Threshold DinÃ¢mico por Parada**

**Problema:** Threshold global (0.45) nÃ£o funciona para todas as paradas

**SoluÃ§Ã£o:**
```python
# Calibrar threshold especÃ­fico por faixa de conversÃ£o histÃ³rica
def get_dynamic_threshold(stop_historical_conversion):
    if stop_historical_conversion > 0.7:
        return 0.3  # Threshold mais baixo para paradas de alta conversÃ£o
    elif stop_historical_conversion > 0.4:
        return 0.4
    else:
        return 0.5  # Threshold mais alto para baixa conversÃ£o

df['threshold'] = df['stop_historical_conversion'].apply(get_dynamic_threshold)
df['prediction'] = (df['prob_ensemble'] > df['threshold']).astype(int)
```

---

### 5ï¸âƒ£ **ESTRATÃ‰GIA 5: Feature de Volume por Parada**

**Problema:** Paradas com muitos eventos podem ter comportamento diferente

**SoluÃ§Ã£o:**
```python
# AgregaÃ§Ãµes avanÃ§adas por parada
stop_stats = df.groupby('gtfs_stop_id').agg({
    'target': ['mean', 'sum', 'std'],  # Taxa, total, variaÃ§Ã£o
    'user_pseudo_id': 'nunique',        # UsuÃ¡rios Ãºnicos
    'event_timestamp': 'count',         # Volume total
    'is_peak_hour': 'mean'              # % eventos no pico
})

stop_stats.columns = ['stop_conversion_rate', 'stop_total_conversions', 
                       'stop_conversion_std', 'stop_unique_users',
                       'stop_event_volume', 'stop_peak_ratio']

df = df.merge(stop_stats, left_on='gtfs_stop_id', right_index=True)

# Feature de volatilidade
df['stop_volatility'] = df['stop_conversion_std'] / (df['stop_conversion_rate'] + 0.01)
```

---

### 6ï¸âƒ£ **ESTRATÃ‰GIA 6: Oversampling Estratificado**

**Problema:** Poucos exemplos de alta conversÃ£o no treino

**SoluÃ§Ã£o:**
```python
from imblearn.over_sampling import SMOTE

# SMOTE apenas em paradas de alta conversÃ£o
high_conversion = df[df['stop_conversion_rate'] > 0.5]
low_conversion = df[df['stop_conversion_rate'] <= 0.5]

# Oversample as de alta conversÃ£o
smote = SMOTE(sampling_strategy=0.3, random_state=42)
X_high_resampled, y_high_resampled = smote.fit_resample(
    high_conversion[features], 
    high_conversion[target]
)

# Combinar
df_balanced = pd.concat([low_conversion, 
                         pd.DataFrame(X_high_resampled, columns=features)])
```

---

### 7ï¸âƒ£ **ESTRATÃ‰GIA 7: Ensemble com Modelo Especializado**

**Problema:** Um modelo sÃ³ nÃ£o captura todos os padrÃµes

**SoluÃ§Ã£o:**
```python
# Treinar 2 modelos:
# Modelo A: Geral (todas as paradas)
# Modelo B: Especializado (sÃ³ paradas > 30% conversÃ£o)

# Modelo especializado
df_high = df[df['stop_historical_conversion'] > 0.3]
model_specialist = lgb.train(params, lgb.Dataset(X_high, y_high))

# PrediÃ§Ã£o combinada
def predict_ensemble(row):
    pred_general = model_general.predict(row)
    
    if row['stop_historical_conversion'] > 0.3:
        pred_specialist = model_specialist.predict(row)
        # Dar mais peso ao especialista
        return 0.3 * pred_general + 0.7 * pred_specialist
    else:
        return pred_general
```

---

## ğŸ“‹ PLANO DE IMPLEMENTAÃ‡ÃƒO (ORDEM DE PRIORIDADE)

### âœ… **FASE 1: Quick Wins (1-2 dias)**
1. âœ… Adicionar `stop_historical_conversion` como feature
2. âœ… Adicionar `stop_density` (densidade de paradas)
3. âœ… Aumentar `scale_pos_weight` para 15-20
4. âœ… Calibrar threshold dinÃ¢mico

**Expectativa:** Erro cair de 19% para 12-15%

---

### âœ… **FASE 2: Melhorias MÃ©dias (3-5 dias)**
5. âœ… Implementar clustering de paradas (DBSCAN)
6. âœ… Adicionar distÃ¢ncia ao CBD
7. âœ… Features de volume/volatilidade por parada
8. âœ… ValidaÃ§Ã£o por faixa de conversÃ£o

**Expectativa:** Erro cair para 8-10%, comeÃ§ar a prever algumas paradas de alta conversÃ£o

---

### ğŸ”„ **FASE 3: AvanÃ§ado (1-2 semanas)**
9. ğŸ”„ Implementar Focal Loss
10. ğŸ”„ SMOTE estratificado
11. ğŸ”„ Modelo especializado (ensemble hÃ­brido)
12. ğŸ”„ Hyperparameter tuning com Optuna

**Expectativa:** Erro < 5%, capturar 70%+ das paradas de alta conversÃ£o

---

## ğŸ¯ MÃ‰TRICAS DE SUCESSO

**Antes (V7):**
- Taxa real: 40.2% (mÃ©dia das top 200)
- PrediÃ§Ã£o: 21.1%
- Erro: 19.1%
- CorrelaÃ§Ã£o: 0.484
- Paradas >50% previstas: **0** (0%)

**Meta V8 (Fase 1):**
- PrediÃ§Ã£o: 30-35%
- Erro: <15%
- CorrelaÃ§Ã£o: >0.60
- Paradas >50% previstas: **15+** (26%)

**Meta V8 (Fase 2):**
- PrediÃ§Ã£o: 35-40%
- Erro: <10%
- CorrelaÃ§Ã£o: >0.75
- Paradas >50% previstas: **35+** (61%)

**Meta V8 (Fase 3):**
- PrediÃ§Ã£o: 38-42%
- Erro: <5%
- CorrelaÃ§Ã£o: >0.85
- Paradas >50% previstas: **45+** (79%)

---

## ğŸš€ PRÃ“XIMOS PASSOS

1. **Criar model_v8_improved.py** com Fase 1
2. **Testar** no mesmo dataset de validaÃ§Ã£o
3. **Comparar** mÃ©tricas V7 vs V8
4. **Iterar** com Fase 2 se Fase 1 funcionar
5. **Gerar** novos mapas com prediÃ§Ãµes V8

Qual fase vocÃª quer que eu implemente primeiro? ğŸ’ª
