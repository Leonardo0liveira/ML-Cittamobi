from google.cloud import bigquery
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score, 
                             recall_score, f1_score, confusion_matrix, classification_report)
from sklearn.model_selection import TimeSeriesSplit
import xgboost as xgb
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

project_id = "proj-ml-469320"
client = bigquery.Client(project=project_id)

# ===========================================================================
# ETAPA 1: CARREGAR DADOS
# ===========================================================================
print(f"\n{'='*70}")
print(f"MODELO V4 ADVANCED - TÃ‰CNICAS AVANÃ‡ADAS")
print(f"{'='*70}")
print(f"ETAPA 1: CARREGANDO DATASET COM AMOSTRAGEM ALEATÃ“RIA")
print(f"{'='*70}")

query = """
    SELECT * FROM `proj-ml-469320.app_cittamobi.dataset-updated` 
    TABLESAMPLE SYSTEM (20 PERCENT)
    LIMIT 200000
"""

print("Carregando 200,000 amostras com amostragem aleatÃ³ria...")
df = client.query(query).to_dataframe()
print(f"âœ“ Dados carregados: {len(df):,} registros")

# ===========================================================================
# ETAPA 2: FEATURE ENGINEERING AVANÃ‡ADO
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 2: FEATURE ENGINEERING AVANÃ‡ADO")
print(f"{'='*70}")

target = "target"

# Criar features de agregaÃ§Ã£o por usuÃ¡rio ANTES da limpeza
print("\nğŸ“Š Criando features de agregaÃ§Ã£o por usuÃ¡rio...")
if 'user_pseudo_id' in df.columns:
    user_agg = df.groupby('user_pseudo_id').agg({
        target: ['mean', 'sum', 'count'],  # Taxa de conversÃ£o, total conversÃµes, frequÃªncia
        'dist_device_stop': ['mean', 'std', 'min', 'max'] if 'dist_device_stop' in df.columns else ['mean'],
        'time_hour': ['mean', 'std'] if 'time_hour' in df.columns else ['mean']
    }).reset_index()
    
    user_agg.columns = ['user_pseudo_id', 'user_conversion_rate', 'user_total_conversions', 
                        'user_total_events', 'user_avg_dist', 'user_std_dist', 
                        'user_min_dist', 'user_max_dist', 'user_avg_hour', 'user_std_hour']
    
    df = df.merge(user_agg, on='user_pseudo_id', how='left')
    print(f"âœ“ Features de usuÃ¡rio criadas: {len(user_agg.columns)-1}")

# Features de agregaÃ§Ã£o por parada
print("\nğŸ“Š Criando features de agregaÃ§Ã£o por parada...")
if 'gtfs_stop_id' in df.columns:
    stop_agg = df.groupby('gtfs_stop_id').agg({
        target: ['mean', 'count'],
        'user_frequency': ['mean', 'median'] if 'user_frequency' in df.columns else ['mean']
    }).reset_index()
    
    stop_agg.columns = ['gtfs_stop_id', 'stop_conversion_rate', 'stop_event_count_agg',
                        'stop_user_freq_mean', 'stop_user_freq_median']
    
    df = df.merge(stop_agg, on='gtfs_stop_id', how='left')
    print(f"âœ“ Features de parada criadas: {len(stop_agg.columns)-1}")

# Features de interaÃ§Ã£o avanÃ§adas
print("\nğŸ“Š Criando features de interaÃ§Ã£o de 2Âª ordem...")
if 'user_conversion_rate' in df.columns and 'stop_conversion_rate' in df.columns:
    df['conversion_interaction'] = df['user_conversion_rate'] * df['stop_conversion_rate']
    
if 'user_avg_dist' in df.columns and 'dist_device_stop' in df.columns:
    df['dist_deviation'] = abs(df['dist_device_stop'] - df['user_avg_dist'])
    df['dist_ratio'] = df['dist_device_stop'] / (df['user_avg_dist'] + 1)

if 'user_frequency' in df.columns and 'stop_event_count_agg' in df.columns:
    df['user_stop_affinity'] = df['user_frequency'] * df['stop_event_count_agg']

print(f"âœ“ Features de interaÃ§Ã£o criadas")

# ===========================================================================
# ETAPA 3: LIMPEZA MODERADA
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 3: LIMPEZA MODERADA DOS DADOS")
print(f"{'='*70}")

print(f"\n=== DistribuiÃ§Ã£o do Target (Original) ===")
target_dist = df[target].value_counts()
print(target_dist)
print(f"ProporÃ§Ã£o classe 0: {target_dist[0]/len(df)*100:.2f}%")
print(f"ProporÃ§Ã£o classe 1: {target_dist[1]/len(df)*100:.2f}%")

df_original_size = len(df)

# Filtros moderados
if 'user_frequency' in df.columns:
    user_freq_threshold = df['user_frequency'].quantile(0.10)
    df = df[df['user_frequency'] >= user_freq_threshold]
    removed = df_original_size - len(df)
    print(f"âœ“ Filtro 1: Removidos {removed:,} registros ({removed/df_original_size*100:.1f}%)")
    df_original_size = len(df)

if 'device_lat' in df.columns and 'device_lon' in df.columns:
    df = df[~((df['device_lat'].isna()) | (df['device_lon'].isna()))]
    df = df[~((df['device_lat'] == 0) & (df['device_lon'] == 0))]
    removed = df_original_size - len(df)
    print(f"âœ“ Filtro 2: Removidos {removed:,} registros ({removed/df_original_size*100:.1f}%)")
    df_original_size = len(df)

if 'dist_device_stop' in df.columns:
    dist_threshold = df['dist_device_stop'].quantile(0.98)
    df = df[df['dist_device_stop'] <= dist_threshold]
    removed = df_original_size - len(df)
    print(f"âœ“ Filtro 3: Removidos {removed:,} registros ({removed/df_original_size*100:.1f}%)")

total_removed = 200000 - len(df)
removal_pct = total_removed / 200000 * 100
print(f"\nâœ“ Total mantido: {len(df):,} ({100-removal_pct:.1f}%)")

# ===========================================================================
# ETAPA 4: PREPARAÃ‡ÃƒO DE FEATURES
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 4: PREPARAÃ‡ÃƒO DE FEATURES")
print(f"{'='*70}")

features_to_drop = ['y_pred', 'y_pred_proba', 'ctm_service_route', 'direction', 'lotacao_proxy_binaria']
X = df.drop(columns=[target] + features_to_drop, errors='ignore')
y = df[target]

# Processar timestamp
if 'event_timestamp' in X.columns:
    X['event_timestamp'] = pd.to_datetime(X['event_timestamp'])
    X['year'] = X['event_timestamp'].dt.year
    X['month'] = X['event_timestamp'].dt.month
    X['day'] = X['event_timestamp'].dt.day
    X['hour'] = X['event_timestamp'].dt.hour
    X['dayofweek'] = X['event_timestamp'].dt.dayofweek
    X['minute'] = X['event_timestamp'].dt.minute
    X['week_of_year'] = X['event_timestamp'].dt.isocalendar().week
    X = X.drop(columns=['event_timestamp'])

# Features cÃ­clicas
if 'time_day_of_month' in X.columns:
    X['day_of_month_sin'] = np.sin(2 * np.pi * X['time_day_of_month'] / 31)
    X['day_of_month_cos'] = np.cos(2 * np.pi * X['time_day_of_month'] / 31)

if 'week_of_year' in X.columns:
    X['week_sin'] = np.sin(2 * np.pi * X['week_of_year'] / 52)
    X['week_cos'] = np.cos(2 * np.pi * X['week_of_year'] / 52)

if 'hour' in X.columns:
    X['hour_sin'] = np.sin(2 * np.pi * X['hour'] / 24)
    X['hour_cos'] = np.cos(2 * np.pi * X['hour'] / 24)

# Label Encoding
categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
if categorical_cols:
    from sklearn.preprocessing import LabelEncoder
    for col in categorical_cols:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col].astype(str))

X = X.replace([np.inf, -np.inf], np.nan)
X = X.fillna(0)

print(f"âœ“ Features totais: {X.shape[1]}")

# ===========================================================================
# ETAPA 5: SELEÃ‡ÃƒO DE FEATURES (TOP 50)
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 5: SELEÃ‡ÃƒO DAS MELHORES FEATURES")
print(f"{'='*70}")

tscv = TimeSeriesSplit(n_splits=2)
for fold, (train_index, test_index) in enumerate(tscv.split(X)):
    X_train_temp, X_test_temp = X.iloc[train_index], X.iloc[test_index]
    y_train_temp, y_test_temp = y.iloc[train_index], y.iloc[test_index]

dtrain_temp = xgb.DMatrix(X_train_temp, label=y_train_temp)
scale_pos_weight = (len(y_train_temp) - y_train_temp.sum()) / y_train_temp.sum()

params_temp = {
    'objective': 'binary:logistic',
    'max_depth': 6,
    'learning_rate': 0.1,
    'eval_metric': 'logloss',
    'seed': 42,
    'scale_pos_weight': scale_pos_weight
}

model_temp = xgb.train(
    params=params_temp,
    dtrain=dtrain_temp,
    num_boost_round=50,
    verbose_eval=False
)

importance_dict = model_temp.get_score(importance_type='gain')
importance_df = pd.DataFrame([
    {'feature': k, 'importance': v} 
    for k, v in importance_dict.items()
]).sort_values('importance', ascending=False)

top_n = 50  # Aumentado para 50
top_features = importance_df.head(top_n)['feature'].tolist()
X_selected = X[top_features].copy()

print(f"âœ“ Features selecionadas: {len(top_features)}")
print(f"âœ“ Top 10 features:")
for i, row in importance_df.head(10).iterrows():
    print(f"   {i+1}. {row['feature']}: {row['importance']:.2f}")

# ===========================================================================
# ETAPA 6: DIVISÃƒO TEMPORAL
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 6: DIVISÃƒO TEMPORAL (TimeSeriesSplit)")
print(f"{'='*70}")

tscv = TimeSeriesSplit(n_splits=3)
X_train, X_test, y_train, y_test = None, None, None, None

for fold, (train_index, test_index) in enumerate(tscv.split(X_selected)):
    X_train, X_test = X_selected.iloc[train_index], X_selected.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    if fold == 2:
        print(f"Fold {fold + 1}: Train={len(X_train):,} | Test={len(X_test):,}")

print(f"\n=== DistribuiÃ§Ã£o Original do Treino ===")
train_dist = y_train.value_counts()
print(f"Classe 0: {train_dist[0]:,} ({train_dist[0]/len(y_train)*100:.2f}%)")
print(f"Classe 1: {train_dist[1]:,} ({train_dist[1]/len(y_train)*100:.2f}%)")
print(f"RazÃ£o (0/1): {train_dist[0]/train_dist[1]:.2f}:1")

# ===========================================================================
# ETAPA 7: ESTRATÃ‰GIAS AVANÃ‡ADAS
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 7: TESTANDO ESTRATÃ‰GIAS AVANÃ‡ADAS")
print(f"{'='*70}")

results = []
base_params = {
    'objective': 'binary:logistic',
    'max_depth': 12,
    'learning_rate': 0.02,
    'subsample': 0.85,
    'colsample_bytree': 0.85,
    'min_child_weight': 5,
    'gamma': 0.1,
    'reg_alpha': 0.01,
    'reg_lambda': 1,
    'eval_metric': 'logloss',
    'seed': 42
}

# ===========================================================================
# ESTRATÃ‰GIA 1: Baseline Otimizado (do V3)
# ===========================================================================
print(f"\n--- EstratÃ©gia 1: BASELINE OTIMIZADO ---")

scale_pos_weight_1 = (len(y_train) - y_train.sum()) / y_train.sum()
params_1 = {**base_params, 'scale_pos_weight': scale_pos_weight_1}

dtrain_1 = xgb.DMatrix(X_train, label=y_train)
dtest_1 = xgb.DMatrix(X_test, label=y_test)

model_1 = xgb.train(
    params=params_1,
    dtrain=dtrain_1,
    num_boost_round=200,
    evals=[(dtest_1, 'test')],
    early_stopping_rounds=20,
    verbose_eval=False
)

y_pred_proba_1 = model_1.predict(dtest_1)
y_pred_1 = (y_pred_proba_1 >= 0.65).astype(int)  # Threshold do V3

results.append({
    'strategy': 'Baseline Otimizado (V3)',
    'train_size': len(X_train),
    'roc_auc': roc_auc_score(y_test, y_pred_proba_1),
    'accuracy': accuracy_score(y_test, y_pred_1),
    'precision': precision_score(y_test, y_pred_1),
    'recall': recall_score(y_test, y_pred_1),
    'f1_score': f1_score(y_test, y_pred_1),
    'f1_macro': f1_score(y_test, y_pred_1, average='macro'),
    'model': model_1,
    'y_pred_proba': y_pred_proba_1
})

print(f"ROC-AUC: {results[-1]['roc_auc']:.4f} | F1-Macro: {results[-1]['f1_macro']:.4f}")

# ===========================================================================
# ESTRATÃ‰GIA 2: Cost-Sensitive Learning (Custos AssimÃ©tricos)
# ===========================================================================
print(f"\n--- EstratÃ©gia 2: COST-SENSITIVE LEARNING ---")

# Aumentar ainda mais o peso da classe minoritÃ¡ria
scale_pos_weight_2 = scale_pos_weight_1 * 1.5  # 50% mais peso
params_2 = {
    **base_params, 
    'scale_pos_weight': scale_pos_weight_2,
    'max_delta_step': 1  # Ajuda com classes desbalanceadas
}

model_2 = xgb.train(
    params=params_2,
    dtrain=dtrain_1,
    num_boost_round=200,
    evals=[(dtest_1, 'test')],
    early_stopping_rounds=20,
    verbose_eval=False
)

y_pred_proba_2 = model_2.predict(dtest_1)
y_pred_2 = (y_pred_proba_2 >= 0.60).astype(int)

results.append({
    'strategy': 'Cost-Sensitive (1.5x weight)',
    'train_size': len(X_train),
    'roc_auc': roc_auc_score(y_test, y_pred_proba_2),
    'accuracy': accuracy_score(y_test, y_pred_2),
    'precision': precision_score(y_test, y_pred_2),
    'recall': recall_score(y_test, y_pred_2),
    'f1_score': f1_score(y_test, y_pred_2),
    'f1_macro': f1_score(y_test, y_pred_2, average='macro'),
    'model': model_2,
    'y_pred_proba': y_pred_proba_2
})

print(f"ROC-AUC: {results[-1]['roc_auc']:.4f} | F1-Macro: {results[-1]['f1_macro']:.4f}")

# ===========================================================================
# ESTRATÃ‰GIA 3: User Frequency Undersampling (SugestÃ£o do Professor)
# ===========================================================================
print(f"\n--- EstratÃ©gia 3: USER FREQUENCY UNDERSAMPLING ---")

# Criar DataFrame combinando X_train, y_train e user_frequency
# Usar reset_index para ter Ã­ndices limpos
X_train_reset = X_train.reset_index(drop=True)
y_train_reset = y_train.reset_index(drop=True)

# Pegar user_frequency do df original usando os Ã­ndices originais de X_train
original_indices = X_train.index
user_freq_series = df.loc[original_indices, 'user_frequency'].reset_index(drop=True)

# Criar DataFrame temporÃ¡rio
df_temp = pd.DataFrame({
    'user_frequency': user_freq_series,
    'target': y_train_reset
})

# Filtrar usuÃ¡rios frequentes (top 60%)
user_freq_threshold = df_temp['user_frequency'].quantile(0.40)
mask_filtered = df_temp['user_frequency'] >= user_freq_threshold

# Separar classes
mask_minority = mask_filtered & (df_temp['target'] == 1)
mask_majority = mask_filtered & (df_temp['target'] == 0)

indices_minority = df_temp[mask_minority].index.tolist()
indices_majority = df_temp[mask_majority].index.tolist()

# Undersampling: ratio 5:1
n_minority = len(indices_minority)
n_majority_keep = int(n_minority * 5)

# Priorizar usuÃ¡rios mais frequentes na classe majoritÃ¡ria
majority_freq = df_temp.loc[indices_majority, 'user_frequency']
sorted_majority_indices = majority_freq.sort_values(ascending=False).index.tolist()
indices_majority_sampled = sorted_majority_indices[:n_majority_keep]

# Combinar Ã­ndices
selected_indices = indices_minority + indices_majority_sampled

# Shuffle
np.random.seed(42)
np.random.shuffle(selected_indices)

# Selecionar X e y usando Ã­ndices posicionais
X_train_3 = X_train_reset.iloc[selected_indices]
y_train_3 = y_train_reset.iloc[selected_indices]

# MÃ©tricas do balanceamento
n_class_0 = (y_train_3 == 0).sum()
n_class_1 = (y_train_3 == 1).sum()
print(f"ApÃ³s filtro e balanceamento:")
print(f"  Classe 0: {n_class_0:,}, Classe 1: {n_class_1:,}")
print(f"  RazÃ£o: {n_class_0/n_class_1:.2f}:1")

scale_pos_weight_3 = n_class_0 / n_class_1
params_3 = {**base_params, 'scale_pos_weight': scale_pos_weight_3}

dtrain_3 = xgb.DMatrix(X_train_3, label=y_train_3)

model_3 = xgb.train(
    params=params_3,
    dtrain=dtrain_3,
    num_boost_round=200,
    evals=[(dtest_1, 'test')],
    early_stopping_rounds=20,
    verbose_eval=False
)

y_pred_proba_3 = model_3.predict(dtest_1)
y_pred_3 = (y_pred_proba_3 >= 0.60).astype(int)

results.append({
    'strategy': 'User Freq Undersampling',
    'train_size': len(X_train_3),
    'roc_auc': roc_auc_score(y_test, y_pred_proba_3),
    'accuracy': accuracy_score(y_test, y_pred_3),
    'precision': precision_score(y_test, y_pred_3),
    'recall': recall_score(y_test, y_pred_3),
    'f1_score': f1_score(y_test, y_pred_3),
    'f1_macro': f1_score(y_test, y_pred_3, average='macro'),
    'model': model_3,
    'y_pred_proba': y_pred_proba_3
})

print(f"ROC-AUC: {results[-1]['roc_auc']:.4f} | F1-Macro: {results[-1]['f1_macro']:.4f}")

# ===========================================================================
# ESTRATÃ‰GIA 4: Ensemble Stacking
# ===========================================================================
print(f"\n--- EstratÃ©gia 4: ENSEMBLE STACKING ---")

# Treinar 3 modelos com diferentes configuraÃ§Ãµes
models_ensemble = []

# Modelo 1: Conservador (alta precision)
params_ens1 = {**base_params, 'scale_pos_weight': scale_pos_weight_1, 'max_depth': 8}
model_ens1 = xgb.train(params_ens1, dtrain_1, num_boost_round=150, verbose_eval=False)
models_ensemble.append(model_ens1)

# Modelo 2: Agressivo (alta recall)
params_ens2 = {**base_params, 'scale_pos_weight': scale_pos_weight_1 * 2, 'max_depth': 15}
model_ens2 = xgb.train(params_ens2, dtrain_1, num_boost_round=150, verbose_eval=False)
models_ensemble.append(model_ens2)

# Modelo 3: Balanceado
params_ens3 = {**base_params, 'scale_pos_weight': scale_pos_weight_1 * 1.3, 'max_depth': 12}
model_ens3 = xgb.train(params_ens3, dtrain_1, num_boost_round=150, verbose_eval=False)
models_ensemble.append(model_ens3)

# VotaÃ§Ã£o ponderada (mÃ©dia das probabilidades)
preds_ensemble = []
for model in models_ensemble:
    preds_ensemble.append(model.predict(dtest_1))

y_pred_proba_4 = np.mean(preds_ensemble, axis=0)
y_pred_4 = (y_pred_proba_4 >= 0.63).astype(int)

results.append({
    'strategy': 'Ensemble Stacking (3 models)',
    'train_size': len(X_train),
    'roc_auc': roc_auc_score(y_test, y_pred_proba_4),
    'accuracy': accuracy_score(y_test, y_pred_4),
    'precision': precision_score(y_test, y_pred_4),
    'recall': recall_score(y_test, y_pred_4),
    'f1_score': f1_score(y_test, y_pred_4),
    'f1_macro': f1_score(y_test, y_pred_4, average='macro'),
    'model': model_1,  # Placeholder
    'y_pred_proba': y_pred_proba_4
})

print(f"ROC-AUC: {results[-1]['roc_auc']:.4f} | F1-Macro: {results[-1]['f1_macro']:.4f}")

# ===========================================================================
# ESTRATÃ‰GIA 5: Feature Engineering Boost + Deep Trees
# ===========================================================================
print(f"\n--- EstratÃ©gia 5: ADVANCED FEATURES + DEEP TREES ---")

params_5 = {
    **base_params,
    'scale_pos_weight': scale_pos_weight_1,
    'max_depth': 18,  # Ãrvores mais profundas
    'min_child_weight': 3,
    'gamma': 0.05,
    'subsample': 0.9,
    'colsample_bytree': 0.9
}

model_5 = xgb.train(
    params=params_5,
    dtrain=dtrain_1,
    num_boost_round=250,
    evals=[(dtest_1, 'test')],
    early_stopping_rounds=25,
    verbose_eval=False
)

y_pred_proba_5 = model_5.predict(dtest_1)
y_pred_5 = (y_pred_proba_5 >= 0.64).astype(int)

results.append({
    'strategy': 'Advanced Features + Deep Trees',
    'train_size': len(X_train),
    'roc_auc': roc_auc_score(y_test, y_pred_proba_5),
    'accuracy': accuracy_score(y_test, y_pred_5),
    'precision': precision_score(y_test, y_pred_5),
    'recall': recall_score(y_test, y_pred_5),
    'f1_score': f1_score(y_test, y_pred_5),
    'f1_macro': f1_score(y_test, y_pred_5, average='macro'),
    'model': model_5,
    'y_pred_proba': y_pred_proba_5
})

print(f"ROC-AUC: {results[-1]['roc_auc']:.4f} | F1-Macro: {results[-1]['f1_macro']:.4f}")

# ===========================================================================
# ETAPA 8: COMPARAÃ‡ÃƒO E SELEÃ‡ÃƒO
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 8: COMPARAÃ‡ÃƒO DAS ESTRATÃ‰GIAS")
print(f"{'='*70}")

results_df = pd.DataFrame([{
    'EstratÃ©gia': r['strategy'],
    'Train Size': f"{r['train_size']:,}",
    'ROC-AUC': f"{r['roc_auc']:.4f}",
    'Accuracy': f"{r['accuracy']:.4f}",
    'Precision': f"{r['precision']:.4f}",
    'Recall': f"{r['recall']:.4f}",
    'F1-Score': f"{r['f1_score']:.4f}",
    'F1-Macro': f"{r['f1_macro']:.4f}"
} for r in results])

print("\n" + results_df.to_string(index=False))

# Selecionar melhor baseado em F1-Macro
best_idx = np.argmax([r['f1_macro'] for r in results])
best_result = results[best_idx]

print(f"\n{'='*70}")
print(f"ğŸ† MELHOR ESTRATÃ‰GIA: {best_result['strategy']}")
print(f"{'='*70}")
print(f"ROC-AUC:   {best_result['roc_auc']:.4f}")
print(f"Accuracy:  {best_result['accuracy']:.4f}")
print(f"Precision: {best_result['precision']:.4f}")
print(f"Recall:    {best_result['recall']:.4f}")
print(f"F1-Score:  {best_result['f1_score']:.4f}")
print(f"F1-Macro:  {best_result['f1_macro']:.4f} â­")

# ===========================================================================
# ETAPA 9: OTIMIZAÃ‡ÃƒO DE THRESHOLD (MELHOR MODELO)
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 9: OTIMIZANDO THRESHOLD")
print(f"{'='*70}")

best_y_pred_proba = best_result['y_pred_proba']
thresholds_to_test = np.arange(0.3, 0.75, 0.05)
threshold_results = []

for thresh in thresholds_to_test:
    y_pred_thresh = (best_y_pred_proba >= thresh).astype(int)
    
    if (y_pred_thresh == 1).sum() > 0:  # Evitar divisÃ£o por zero
        prec = precision_score(y_test, y_pred_thresh)
        rec = recall_score(y_test, y_pred_thresh)
        f1 = f1_score(y_test, y_pred_thresh)
        f1_macro = f1_score(y_test, y_pred_thresh, average='macro')
        
        threshold_results.append({
            'threshold': thresh,
            'precision': prec,
            'recall': rec,
            'f1_score': f1,
            'f1_macro': f1_macro
        })
        
        print(f"Threshold={thresh:.2f} | Prec={prec:.3f} | Rec={rec:.3f} | F1={f1:.3f} | F1-Macro={f1_macro:.3f}")

best_threshold = max(threshold_results, key=lambda x: x['f1_macro'])
print(f"\nâœ“ Melhor threshold: {best_threshold['threshold']:.2f} (F1-Macro={best_threshold['f1_macro']:.4f})")

y_pred_final = (best_y_pred_proba >= best_threshold['threshold']).astype(int)

# ===========================================================================
# ETAPA 10: MÃ‰TRICAS FINAIS
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 10: MÃ‰TRICAS FINAIS - V4 ADVANCED")
print(f"{'='*70}")

roc_auc_final = roc_auc_score(y_test, best_y_pred_proba)
accuracy_final = accuracy_score(y_test, y_pred_final)
precision_final = precision_score(y_test, y_pred_final)
recall_final = recall_score(y_test, y_pred_final)
f1_final = f1_score(y_test, y_pred_final)
f1_macro_final = f1_score(y_test, y_pred_final, average='macro')

print(f"\n=== MÃ©tricas Finais ===")
print(f"EstratÃ©gia: {best_result['strategy']}")
print(f"Threshold: {best_threshold['threshold']:.2f}")
print(f"")
print(f"ROC-AUC:     {roc_auc_final:.4f}")
print(f"Accuracy:    {accuracy_final:.4f} ({accuracy_final*100:.2f}%)")
print(f"Precision:   {precision_final:.4f}")
print(f"Recall:      {recall_final:.4f}")
print(f"F1-Score:    {f1_final:.4f}")
print(f"F1-Macro:    {f1_macro_final:.4f} â­")

cm = confusion_matrix(y_test, y_pred_final)
print(f"\n=== Matriz de ConfusÃ£o ===")
print(f"                 Predito")
print(f"                 0      1")
print(f"Real  0       {cm[0,0]:6d} {cm[0,1]:6d}")
print(f"      1       {cm[1,0]:6d} {cm[1,1]:6d}")

# ===========================================================================
# ETAPA 11: VISUALIZAÃ‡Ã•ES
# ===========================================================================
print(f"\n{'='*70}")
print(f"ETAPA 11: GERANDO VISUALIZAÃ‡Ã•ES")
print(f"{'='*70}")

# ComparaÃ§Ã£o de estratÃ©gias
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

metrics = ['roc_auc', 'precision', 'recall', 'f1_macro']
titles = ['ROC-AUC', 'Precision', 'Recall', 'F1-Macro']
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd']

for idx, (metric, title) in enumerate(zip(metrics, titles)):
    ax = axes[idx // 2, idx % 2]
    values = [r[metric] for r in results]
    strategies = [r['strategy'][:20] for r in results]  # Truncar nomes
    
    bars = ax.barh(range(len(strategies)), values, color=colors[idx], alpha=0.7)
    ax.set_yticks(range(len(strategies)))
    ax.set_yticklabels(strategies, fontsize=9)
    ax.set_xlabel(title)
    ax.set_title(f'ComparaÃ§Ã£o: {title}')
    ax.grid(axis='x', alpha=0.3)
    
    # Destacar melhor
    if metric == 'f1_macro':
        best_idx_metric = np.argmax(values)
        bars[best_idx_metric].set_color('#2ca02c')
        bars[best_idx_metric].set_edgecolor('black')
        bars[best_idx_metric].set_linewidth(2)
    
    # Adicionar valores
    for i, v in enumerate(values):
        ax.text(v, i, f' {v:.3f}', va='center', fontsize=8)

plt.tight_layout()
plt.savefig('v4_strategies_comparison.png', dpi=300, bbox_inches='tight')
print("âœ“ v4_strategies_comparison.png")

# Matriz de confusÃ£o
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Classe 0', 'Classe 1'],
            yticklabels=['Classe 0', 'Classe 1'])
plt.title(f'Matriz de ConfusÃ£o - V4 Advanced\n{best_result["strategy"]}')
plt.ylabel('Real')
plt.xlabel('Predito')
plt.tight_layout()
plt.savefig('confusion_matrix_v4.png', dpi=300, bbox_inches='tight')
print("âœ“ confusion_matrix_v4.png")

# Salvar melhor modelo
best_result['model'].save_model('xgboost_model_v4_advanced.json')
print("âœ“ xgboost_model_v4_advanced.json")

# ===========================================================================
# RESUMO FINAL
# ===========================================================================
print(f"\n{'='*70}")
print(f"ğŸ‰ V4 ADVANCED - RESUMO FINAL")
print(f"{'='*70}")

print(f"\nğŸ”¬ EstratÃ©gias Testadas:")
for i, r in enumerate(results, 1):
    symbol = "â­" if r == best_result else "  "
    print(f"{symbol} {i}. {r['strategy']:35s} | F1-Macro: {r['f1_macro']:.4f}")

print(f"\nğŸ“ˆ ComparaÃ§Ã£o com VersÃµes Anteriores:")
print(f"   V1: ROC-AUC 0.8367, F1-Macro ~0.65")
print(f"   V3: ROC-AUC 0.9283, F1-Macro 0.7050")
print(f"   V3 Enhanced: ROC-AUC 0.9324, F1-Macro 0.7143")
print(f"   V4 Advanced: ROC-AUC {roc_auc_final:.4f}, F1-Macro {f1_macro_final:.4f} â­")

improvement_v3 = ((f1_macro_final - 0.7143) / 0.7143) * 100
if f1_macro_final > 0.7143:
    print(f"   âœ… Melhoria sobre V3 Enhanced: +{improvement_v3:.1f}%")
else:
    print(f"   â¡ï¸ V4 vs V3 Enhanced: {improvement_v3:.1f}%")

print(f"\nğŸ“Š Principais Melhorias do V4:")
print(f"   âœ“ Features de agregaÃ§Ã£o por usuÃ¡rio e parada")
print(f"   âœ“ InteraÃ§Ãµes de 2Âª ordem")
print(f"   âœ“ Cost-sensitive learning")
print(f"   âœ“ User frequency undersampling")
print(f"   âœ“ Ensemble stacking")
print(f"   âœ“ 50 features (vs 40 no V3)")

print(f"\n{'='*70}")
