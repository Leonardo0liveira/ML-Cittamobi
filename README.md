# üöç Projeto Machine Learning - Cittamobi Forecast

## üìã Vis√£o Geral

Projeto de previs√£o de convers√£o de eventos de usu√°rios de transporte p√∫blico utilizando m√∫ltiplos algoritmos de Machine Learning com foco em otimiza√ß√£o e ensemble methods.

**Objetivo**: Prever se um usu√°rio ir√° converter (realizar uma a√ß√£o desejada) com base em seus padr√µes de uso e caracter√≠sticas dos eventos.

---

## üìä Resultados - Modelos Otimizados

| Modelo | ROC-AUC | F1-Score | F1-Macro | Accuracy | Precision | Recall | Status |
|--------|---------|----------|----------|----------|-----------|--------|--------|
| **Random Forest** | **80.83%** | **40.85%** | **66.48%** | **86.41%** | **33.71%** | **52.31%** | üèÜ **Melhor** |
| **CatBoost** | **80.40%** | **38.48%** | **66.48%** | **83.98%** | **28.38%** | **61.66%** | ü•à 2¬∫ lugar |
| **Stacking Ensemble** | **80.48%** | **39.75%** | **66.37%** | **86.06%** | **32.27%** | **52.38%** | üèÖ 3¬∫ lugar |
| SVM | 79.92% | 40.31% | 66.21% | 86.24% | 33.71% | 50.55% | ‚úÖ |
| SGD (Hinge) | 77.47% | 37.83% | 64.55% | 85.46% | 34.94% | 42.43% | ‚úÖ |
| Naive Bayes | 77.67% | 28.89% | 61.65% | 70.50% | 17.74% | 78.92% | ‚úÖ |
| KNN (K=51) | 75.33% | 39.61% | 64.83% | 84.80% | 40.33% | 38.93% | ‚úÖ |
| Decision Tree | 75.02% | 34.38% | 62.84% | 82.56% | 27.55% | 46.64% | ‚úÖ |

**T√©cnicas Aplicadas**: Undersampling (2:1), TimeSeriesSplit CV (5 folds), StandardScaler normalization

---

## üìÅ Estrutura do Projeto (Cookie Cutter Data Science)

```
Projeto Machine Learning/
‚îú‚îÄ‚îÄ README.md                      # Documenta√ß√£o principal
‚îú‚îÄ‚îÄ environment.yml               # Ambiente conda
‚îú‚îÄ‚îÄ INDEX.md                      # √çndice de documenta√ß√£o
‚îú‚îÄ‚îÄ ORGANIZACAO.md               # Detalhes da organiza√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Dados em diferentes est√°gios
‚îÇ   ‚îú‚îÄ‚îÄ 01_raw/                 # Dados brutos do BigQuery
‚îÇ   ‚îú‚îÄ‚îÄ 02_interim/             # Dados com expanding windows
‚îÇ   ‚îî‚îÄ‚îÄ 03_processed/           # Dados prontos para modelagem
‚îÇ
‚îú‚îÄ‚îÄ models/                      # C√≥digo dos modelos
‚îÇ   ‚îú‚îÄ‚îÄ SGDClassifier/          # SGD com 3 loss functions
‚îÇ   ‚îú‚îÄ‚îÄ KNN/                    # K-Nearest Neighbors
‚îÇ   ‚îú‚îÄ‚îÄ DecisionTrees/          # Decision Tree com m√∫ltiplas profundidades
‚îÇ   ‚îú‚îÄ‚îÄ NaiveBayes/             # Gaussian, Multinomial, Bernoulli
‚îÇ   ‚îú‚îÄ‚îÄ SVM/                    # Support Vector Machine
‚îÇ   ‚îú‚îÄ‚îÄ RandomForest/           # Random Forest (melhor modelo)
‚îÇ   ‚îú‚îÄ‚îÄ catboost/               # CatBoost gradient boosting
‚îÇ   ‚îú‚îÄ‚îÄ lightgbm/               # LightGBM (experimental)
‚îÇ   ‚îú‚îÄ‚îÄ stacking_ensemble.py    # Ensemble RF+CB+SGD
‚îÇ   ‚îú‚îÄ‚îÄ all_models_comparison.py # Compara√ß√£o unificada
‚îÇ   ‚îú‚îÄ‚îÄ trained/                # Modelos salvos (.pkl, .json)
‚îÇ   ‚îú‚îÄ‚îÄ predictions/            # Predi√ß√µes dos modelos
‚îÇ   ‚îî‚îÄ‚îÄ archive/                # Vers√µes antigas (v1-v4)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # Notebooks e scripts de an√°lise
‚îÇ   ‚îú‚îÄ‚îÄ exploratory/            # An√°lise explorat√≥ria, testes
‚îÇ   ‚îî‚îÄ‚îÄ final/                  # Notebooks finalizados
‚îÇ
‚îú‚îÄ‚îÄ reports/                     # Resultados e an√°lises
‚îÇ   ‚îú‚îÄ‚îÄ figures/                # Visualiza√ß√µes (ROC, confusion matrix, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ model_evaluations/      # Relat√≥rios .txt, .csv, .md
‚îÇ
‚îú‚îÄ‚îÄ src/                        # C√≥digo fonte reutiliz√°vel
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/                   # Scripts de carregamento de dados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ features/               # Engenharia de features
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ models/                 # Utilit√°rios de modelagem
‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îî‚îÄ‚îÄ docs/                       # Documenta√ß√£o detalhada
    ‚îú‚îÄ‚îÄ ANALISE_RESULTADOS.md
    ‚îú‚îÄ‚îÄ COMPARACAO_V1_V2.md
    ‚îú‚îÄ‚îÄ GUIA_DE_USO.md
    ‚îî‚îÄ‚îÄ V3_ENHANCED_EXPLICACAO.md

---

## üöÄ Como Usar

### 1. Configurar Ambiente

```bash
conda env create -f environment.yml
conda activate cittamobi-forecast
```

### 2. Executar Modelos

#### Modelos Individuais
```bash
# Random Forest (melhor modelo - 80.83% ROC-AUC)
cd models/RandomForest
python random_forest_optimized.py

# CatBoost (segundo melhor - 80.40% ROC-AUC)
cd models/catboost
python catboost_optimized.py

# Outros modelos
cd models/SGDClassifier && python sgd_optimized.py
cd models/SVM && python svm_optimized.py
cd models/KNN && python knn_optimized.py
cd models/NaiveBayes && python nb_optimized.py
cd models/DecisionTrees && python decision_tree_optimized.py
```

#### Ensemble Stacking (80.48% ROC-AUC)
```bash
python models/stacking_ensemble.py
```

#### Compara√ß√£o de Todos os Modelos
```bash
python models/all_models_comparison.py
```

### 3. Ver Resultados

- **Visualiza√ß√µes**: `reports/figures/` (ROC curves, confusion matrices, feature importance)
- **Relat√≥rios**: `reports/model_evaluations/` (classification reports .txt, results .csv)
- **Compara√ß√µes**: `reports/model_evaluations/modelos_otimizados_comparacao.md`
- **Modelos Salvos**: `models/*/xgboost_model_*.json` ou `models/trained/`

---

## üìö Documenta√ß√£o

### Guias de Uso
- **[GUIA_DE_USO.md](docs/GUIA_DE_USO.md)**: Como executar e interpretar os modelos
- **[INDEX.md](INDEX.md)**: √çndice completo da documenta√ß√£o
- **[ORGANIZACAO.md](ORGANIZACAO.md)**: Detalhes da organiza√ß√£o do projeto

### An√°lises T√©cnicas
- **[ANALISE_RESULTADOS.md](docs/ANALISE_RESULTADOS.md)**: An√°lise detalhada dos resultados
- **[COMPARACAO_V1_V2.md](docs/COMPARACAO_V1_V2.md)**: Compara√ß√£o entre vers√µes iniciais
- **[V3_ENHANCED_EXPLICACAO.md](docs/V3_ENHANCED_EXPLICACAO.md)**: Explica√ß√£o da v3
- **[V4_EXPLICACAO.md](docs/V4_EXPLICACAO.md)**: Explica√ß√£o da v4

---

## üîç Destaques dos Modelos

### Random Forest (Recomendado para Produ√ß√£o)
- ‚úÖ **Melhor ROC-AUC**: 80.83%
- ‚úÖ **Balanceamento**: 52.31% recall, 33.71% precision
- ‚úÖ **Estabilidade**: CV 81.00% ¬± 1.17%
- üìä **Features mais importantes**: stop_event_rate (13.17%), stop_density (12.05%)

### CatBoost (Melhor Recall)
- ‚úÖ **Alto Recall**: 61.66% (melhor detec√ß√£o de convers√µes)
- ‚úÖ **ROC-AUC**: 80.40%
- ‚úÖ **Velocidade**: Treinamento r√°pido (6.9s)
- üéØ **Quando usar**: Maximizar detec√ß√£o de convers√µes, tolerar falsos positivos

### Stacking Ensemble (Ensemble Learning)
- ‚úÖ **Combina√ß√£o**: Random Forest + CatBoost + SGD ‚Üí Logistic Regression
- ‚úÖ **ROC-AUC**: 80.48%
- ‚úÖ **Robustez**: Combina pontos fortes de 3 modelos
- üéØ **Quando usar**: Maximizar confiabilidade, aceitar maior complexidade

---

## üõ†Ô∏è T√©cnicas Aplicadas

### Tratamento de Desbalanceamento
- **Undersampling**: Propor√ß√£o 2:1 (classe majorit√°ria : classe minorit√°ria)
- **Efeito**: Melhoria de recall de ~16% ‚Üí 52% no Random Forest

### Valida√ß√£o Cruzada
- **M√©todo**: TimeSeriesSplit com 5 folds
- **M√©trica**: ROC-AUC (adequada para classes desbalanceadas)
- **Resultado**: Valida√ß√£o robusta com baixa vari√¢ncia (¬± 1-2%)

### Normaliza√ß√£o
- **StandardScaler**: Aplicado em SVM e SGD
- **Sem normaliza√ß√£o**: Random Forest, CatBoost, Decision Tree (robustos a escala)

---

## üìà Pr√≥ximos Passos

### Melhorias Potenciais
- [ ] Testar SMOTE (oversampling sint√©tico) como alternativa ao undersampling
- [ ] Hyperparameter tuning com Optuna ou Grid Search
- [ ] Feature selection com SHAP values ou permutation importance
- [ ] Calibra√ß√£o de probabilidades (Platt scaling, isotonic regression)
- [ ] Threshold optimization para maximizar F1-Score ou m√©trica de neg√≥cio

### Deployment
- [ ] Criar API REST com FastAPI para servir modelos
- [ ] Containerizar com Docker
- [ ] Implementar monitoramento de drift de dados
- [ ] Configurar CI/CD para retreinamento autom√°tico
- [ ] Adicionar testes unit√°rios para pipeline de dados

---

## üìä Dataset

**Fonte**: BigQuery - Eventos de usu√°rios de transporte p√∫blico  
**Features**: Expanding windows (agrega√ß√µes temporais de eventos)  
**Target**: Convers√£o (0 = n√£o converteu, 1 = converteu)  
**Desbalanceamento**: 8.87:1 (classe 0 : classe 1)

### Features Principais
- `stop_event_rate`: Taxa de eventos de parada (correla√ß√£o +0.38 com target)
- `stop_density`: Densidade de paradas no per√≠odo
- `stop_event_count`: Contagem total de eventos de parada
- `hour`: Hora do dia (pico de convers√£o √†s 18h com 16.81%)

---

## ü§ù Contribuindo

Para contribuir com este projeto:

1. Clone o reposit√≥rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

---

## üìÑ Licen√ßa

Este projeto √© de uso interno da Cittamobi.

---

## üë• Autores

**Equipe de Data Science - Cittamobi**

Para d√∫vidas ou sugest√µes, consulte a documenta√ß√£o em `docs/` ou abra uma issue no reposit√≥rio.
- **4 agrega√ß√µes por parada**: conversion_rate, event_count, user_frequency
- **Intera√ß√µes de 2¬™ ordem**: conversion_interaction, dist_deviation, user_stop_affinity
- **50 features** selecionadas (vs 40 no V3)

### Hiperpar√¢metros Vencedores:
```python
{
    'max_depth': 18,           # √Årvores profundas para capturar intera√ß√µes complexas
    'learning_rate': 0.02,
    'min_child_weight': 3,
    'subsample': 0.85,
    'colsample_bytree': 0.85,
    'num_boost_round': 250,
    'early_stopping_rounds': 25
}
```

### Threshold √ìtimo:
- **0.65** para maximizar F1-Macro (0.7760)

---

## üìà Evolu√ß√£o do Projeto

### V1 - Baseline (POC)
- Primeira abordagem
- ROC-AUC: 0.8367
- Problemas: baixa precis√£o, muitos falsos positivos

### V2 - Enhanced
- Limpeza agressiva dos dados
- **Problema cr√≠tico**: removeu 87.9% dos dados
- ROC-AUC caiu para 0.7961

### V3 - Hybrid + Enhanced
- Limpeza moderada (11.6% removido)
- Feature selection (top 40)
- ROC-AUC: 0.9283 (+10.9% vs V1)
- Enhanced: testou 4 t√©cnicas de balanceamento
  - Baseline (scale_pos_weight) foi o melhor

### V4 - Advanced üèÜ
- Feature engineering avan√ßado
- 5 estrat√©gias testadas
- **Advanced Features + Deep Trees venceu**
- **ROC-AUC: 0.9731** (+16.3% vs V1)
- **Precision: 0.59** (‚úÖ alcan√ßou meta > 0.50)

---

## üî¨ Tecnologias Utilizadas

- **Python 3.12**
- **XGBoost**: Modelo de gradient boosting
- **Google BigQuery**: Source de dados (TABLESAMPLE 20%)
- **imbalanced-learn**: T√©cnicas de balanceamento (SMOTE, Tomek, etc.)
- **scikit-learn**: M√©tricas e valida√ß√£o (TimeSeriesSplit)
- **pandas, numpy**: Manipula√ß√£o de dados
- **matplotlib, seaborn**: Visualiza√ß√µes

---

## üìö Documenta√ß√£o

- **[GUIA_DE_USO.md](docs/GUIA_DE_USO.md)**: Como executar cada vers√£o
- **[V4_EXPLICACAO.md](docs/V4_EXPLICACAO.md)**: Detalhes t√©cnicos do V4
- **[V3_ENHANCED_EXPLICACAO.md](docs/V3_ENHANCED_EXPLICACAO.md)**: T√©cnicas de balanceamento
- **[ANALISE_RESULTADOS.md](docs/ANALISE_RESULTADOS.md)**: An√°lises detalhadas
- **[COMPARACAO_V1_V2.md](docs/COMPARACAO_V1_V2.md)**: Comparativo inicial

---

## üë®‚Äçüíª Autor

**Stefano**  
Projeto Machine Learning - IBMEC  
Outubro 2025

---

## üìù Notas

- Dataset: ~200k amostras (20% do total via TABLESAMPLE)
- Classe desbalanceada: ~92% classe 0, ~8% classe 1 (ratio 12:1)
- Valida√ß√£o temporal: TimeSeriesSplit (3 folds)
- Threshold otimizado: 0.65 (vs default 0.50)

**Modelo de produ√ß√£o recomendado**: V4 Advanced - Strategy 5
