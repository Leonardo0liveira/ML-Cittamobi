# üìä Relat√≥rio Comparativo: Modelo V1 vs V2 Enhanced

## üéØ Resumo Executivo

Compara√ß√£o entre o modelo baseline (V1) com 50k amostras e o modelo enhanced (V2) com limpeza rigorosa de dados, 500k amostras iniciais e feature engineering avan√ßado.

---

## üìà Compara√ß√£o de Performance

| M√©trica | V1 (Baseline) | V2 (Enhanced) | Diferen√ßa | Interpreta√ß√£o |
|---------|---------------|---------------|-----------|---------------|
| **ROC-AUC** | 0.8367 | 0.7961 | **-0.0406** | ‚ö†Ô∏è Redu√ß√£o de 4.8% |
| **Accuracy** | 89.02% | 86.62% | **-2.40%** | ‚ö†Ô∏è Ligeira queda |
| **Precision** | 45.19% | 41.99% | **-3.20%** | ‚ö†Ô∏è Ligeira queda |
| **Recall** | 51.21% | 48.89% | **-2.32%** | ‚ö†Ô∏è Ligeira queda |
| **F1-Score** | 0.4801 | 0.4518 | **-0.0283** | ‚ö†Ô∏è Redu√ß√£o de 5.9% |
| **Threshold** | 0.6 | 0.5 | -0.1 | Voltou ao padr√£o |

---

## üìä An√°lise dos Dados

### **V1 - Dataset Baseline**
```
Amostras: 50,000
Features: 38
Filtros: Apenas remo√ß√£o de data leakage
Balanceamento: 90.23% / 9.77%
```

### **V2 - Dataset Enhanced**
```
Amostras iniciais: 500,000
Amostras ap√≥s filtros: 60,498 (12.1% mantidos)
Features: 49 (+11 novas)
Filtros aplicados:
  ‚úì Usu√°rios com baixa frequ√™ncia: -24,848
  ‚úì Localiza√ß√£o inv√°lida: -81
  ‚úì Dist√¢ncia muito alta: -3,754
  ‚úì Headway inv√°lido: 0
  ‚úì Paradas com poucos eventos: -10,819
  ‚úì Total removido: 439,502 (87.9%)

Balanceamento final: 89.42% / 10.58%
```

---

## üîç An√°lise Detalhada

### **1. Por que V2 teve Performance Inferior?**

#### **Hip√≥tese 1: Overfitting no V1** ‚ùå
- V1 tinha apenas 50k amostras
- V2 com limpeza rigorosa ficou com 60k amostras de MAIOR qualidade
- Se fosse overfitting, V2 deveria ter performance melhor ‚Üí N√£o √© o caso

#### **Hip√≥tese 2: Dados muito "limpos" ‚úÖ PROV√ÅVEL**
- **87.9% dos dados foram removidos** (de 500k ‚Üí 60k)
- Removemos usu√°rios casuais, eventos com erro de GPS, etc.
- **Dataset V2 √© muito mais homog√™neo** ‚Üí Menos varia√ß√£o nos padr√µes
- O modelo V1 se beneficiava da "sujeira" dos dados para generalizar melhor

#### **Hip√≥tese 3: Distribui√ß√£o Diferente dos Dados** ‚úÖ PROV√ÅVEL
```
V1: LIMIT 50000 (primeiras 50k linhas)
V2: LIMIT 500000 + filtros rigorosos (diferentes subconjuntos)

A query LIMIT no BigQuery n√£o √© determin√≠stica!
Dados podem ser de per√≠odos/regi√µes diferentes!
```

#### **Hip√≥tese 4: Complexidade Excessiva** ‚ö†Ô∏è POSS√çVEL
- V2 tem 49 features vs 38 no V1 (+11 features)
- Mais features de intera√ß√£o podem ter introduzido ru√≠do
- Algumas features criadas podem n√£o agregar valor

---

## üéØ Matriz de Confus√£o Comparativa

### **V1 - Modelo Baseline (threshold=0.6)**
```
                Predito
                0      1
Real  0     13,991  1,025  ‚Üê 1,025 Falsos Positivos (6.8%)
      1        805    845  ‚Üê 805 Falsos Negativos (48.8%)
```

### **V2 - Modelo Enhanced (threshold=0.5)**
```
                Predito
                0      1
Real  0     12,266  1,152  ‚Üê 1,152 Falsos Positivos (8.6%) ‚¨ÜÔ∏è Pior
      1        872    834  ‚Üê 872 Falsos Negativos (51.1%) ‚¨ÜÔ∏è Pior
```

**Observa√ß√£o:** V2 tem MAIS erros em ambas categorias!

---

## üí° Insights e Descobertas

### **1. Limpeza de Dados ‚â† Sempre Melhor**
- Remover 87.9% dos dados foi **muito agressivo**
- Dataset "limpo" demais pode **reduzir diversidade** necess√°ria para generaliza√ß√£o
- O "ru√≠do" nos dados pode conter padr√µes reais de comportamento do usu√°rio

### **2. Quantidade vs Qualidade**
- V1: 50k amostras "sujas" ‚Üí ROC-AUC 0.8367
- V2: 60k amostras "limpas" ‚Üí ROC-AUC 0.7961
- **Conclus√£o:** Nem sempre "mais limpo" significa "melhor"

### **3. Problema de Amostragem**
- `LIMIT` no BigQuery n√£o garante amostragem representativa
- V1 e V2 podem ter dados de **per√≠odos/regi√µes diferentes**
- Solu√ß√£o: Usar `ORDER BY RAND()` ou `TABLESAMPLE`

### **4. Feature Engineering**
- **11 novas features criadas**, mas performance piorou
- Poss√≠veis features redundantes ou com ru√≠do
- Necessidade de **sele√ß√£o de features** (ex: SHAP, permutation importance)

---

## üîß Recomenda√ß√µes para V3

### **Estrat√©gia 1: Limpeza Moderada**
```python
# Em vez de remover 87.9%, tentar remover apenas 30-40%
# Filtros mais brandos:

# 1. Usu√°rios com baixa frequ√™ncia (Q10 em vez de Q25)
user_freq_threshold = df['user_frequency'].quantile(0.10)

# 2. Dist√¢ncia (Q98 em vez de Q95)
dist_threshold = df['dist_device_stop'].quantile(0.98)

# 3. Paradas (Q10 em vez de Q20)
stop_threshold = df['stop_event_count'].quantile(0.10)
```

### **Estrat√©gia 2: Amostragem Aleat√≥ria**
```sql
-- Query melhorada com amostragem aleat√≥ria
SELECT * FROM `proj-ml-469320.app_cittamobi.dataset-updated` 
TABLESAMPLE SYSTEM (10 PERCENT)  -- 10% aleat√≥rio da tabela
LIMIT 200000
```

### **Estrat√©gia 3: Sele√ß√£o de Features**
```python
# Usar apenas top 30 features mais importantes
from xgboost import plot_importance
importance = model.get_score(importance_type='gain')
top_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:30]
```

### **Estrat√©gia 4: Ensemble com V1 e V2**
```python
# Combinar predi√ß√µes dos dois modelos
pred_final = 0.6 * pred_v1 + 0.4 * pred_v2
```

---

## üìä Features Criadas em V2

### **Novas Features (11 total):**

1. **minute** - Minuto da hora
2. **week_of_year** - Semana do ano
3. **hour_x_dayofweek** - Intera√ß√£o hora x dia da semana
4. **dist_x_peak_enhanced** - Dist√¢ncia x pico (melhorada)
5. **event_rate_normalized** - Taxa de eventos normalizada
6. **headway_per_hour** - Headway por hora
7. **event_density** - Densidade de eventos
8. **day_of_month_sin** - Componente c√≠clico do dia
9. **day_of_month_cos** - Componente c√≠clico do dia
10. **week_sin** - Componente c√≠clico da semana
11. **week_cos** - Componente c√≠clico da semana

**An√°lise:** Algumas podem ser redundantes (ex: j√° existem hour_sin/hour_cos)

---

## üèÜ Conclus√£o

### **Vencedor: V1 (Modelo Baseline)**

| Aspecto | V1 | V2 |
|---------|----|----|
| **Performance** | ‚úÖ Melhor (ROC-AUC 0.8367) | ‚ùå Inferior (ROC-AUC 0.7961) |
| **Simplicidade** | ‚úÖ 38 features | ‚ö†Ô∏è 49 features (mais complexo) |
| **Tempo de treino** | ‚úÖ Mais r√°pido (50k samples) | ‚ö†Ô∏è Mais lento (60k samples) |
| **Interpretabilidade** | ‚úÖ Mais simples | ‚ö†Ô∏è Mais complexo |

### **Li√ß√µes Aprendidas:**

1. ‚úÖ **Nem sempre "mais dados" ou "dados mais limpos" = Melhor modelo**
2. ‚úÖ **Filtros muito rigorosos podem remover variabilidade necess√°ria**
3. ‚úÖ **Feature engineering excessivo pode introduzir ru√≠do**
4. ‚úÖ **Amostragem n√£o aleat√≥ria (LIMIT) pode enviesar resultados**

### **Pr√≥ximos Passos:**

1. **V3: Vers√£o H√≠brida**
   - Usar 200k amostras com `TABLESAMPLE`
   - Filtros moderados (remover 30-40%)
   - Selecionar top 35 features (entre V1 e V2)

2. **An√°lise de SHAP Values**
   - Entender quais features realmente importam
   - Remover features redundantes

3. **Valida√ß√£o Cruzada Temporal**
   - Usar m√∫ltiplos per√≠odos de tempo
   - Garantir robustez temporal

4. **Ensemble**
   - Combinar V1 e V2
   - Pode capturar o melhor de ambos

---

## üìÅ Arquivos Gerados

### **V1:**
- `xgboost_model_optimized.json`
- `confusion_matrix.png`
- `roc_curve.png`
- `threshold_analysis.png`
- `feature_importance.png`

### **V2:**
- `xgboost_model_v2_enhanced.json`
- `confusion_matrix_v2.png`
- `roc_curve_v2.png`
- `threshold_analysis_v2.png`
- `feature_importance_v2.png`

---

## üéì Recomenda√ß√£o Final

**Para produ√ß√£o imediata: USE O MODELO V1**

- ROC-AUC superior (0.8367 vs 0.7961)
- Mais simples e r√°pido
- Melhor generaliza√ß√£o
- Threshold otimizado (0.6)

**Para pesquisa/melhoria: Continue experimentando V3**

- Implementar as estrat√©gias sugeridas
- Testar amostragem aleat√≥ria
- Reduzir agressividade dos filtros
- Fazer sele√ß√£o de features

---

**Data do Relat√≥rio:** 29 de Outubro de 2025  
**Analista:** GitHub Copilot  
**Modelos Comparados:** V1 (Baseline) vs V2 (Enhanced)
