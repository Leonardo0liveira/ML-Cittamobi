# üöÄ Projeto Machine Learning - Cittamobi Forecast

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Estrutura do Projeto](#estrutura-do-projeto)
3. [Modelos Desenvolvidos](#modelos-desenvolvidos)
4. [Resultados](#resultados)
5. [Como Usar](#como-usar)
6. [Documenta√ß√£o](#documenta√ß√£o)

---

## üéØ Vis√£o Geral

Projeto de Machine Learning para previs√£o de eventos usando XGBoost para classifica√ß√£o bin√°ria. O projeto passou por m√∫ltiplas itera√ß√µes, incluindo limpeza de data leakage, otimiza√ß√£o de hiperpar√¢metros, feature engineering avan√ßado e compara√ß√£o de diferentes estrat√©gias de pr√©-processamento.

**Problema:** Classifica√ß√£o bin√°ria desbalanceada (90% classe 0 / 10% classe 1)  
**Algoritmo:** XGBoost (Binary Classification)  
**Dataset:** Google BigQuery (proj-ml-469320.app_cittamobi.dataset-updated)

---

## üìÇ Estrutura do Projeto

```
Projeto Machine Learning/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ C√≥digo
‚îÇ   ‚îú‚îÄ‚îÄ poc.py                      # Modelo V1 Otimizado (RECOMENDADO)
‚îÇ   ‚îî‚îÄ‚îÄ model_v2_enhanced.py        # Modelo V2 com limpeza rigorosa
‚îÇ
‚îú‚îÄ‚îÄ üìä Documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ README.md                   # Este arquivo
‚îÇ   ‚îú‚îÄ‚îÄ ANALISE_RESULTADOS.md       # An√°lise detalhada do V1
‚îÇ   ‚îú‚îÄ‚îÄ COMPARACAO_V1_V2.md         # Compara√ß√£o V1 vs V2
‚îÇ   ‚îî‚îÄ‚îÄ GUIA_DE_USO.md              # Guia completo de uso
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ Modelos Treinados
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_model_optimized.json      # V1 - 4.1 MB (RECOMENDADO)
‚îÇ   ‚îî‚îÄ‚îÄ xgboost_model_v2_enhanced.json    # V2 - 10 MB
‚îÇ
‚îî‚îÄ‚îÄ üìà Visualiza√ß√µes
    ‚îú‚îÄ‚îÄ confusion_matrix.png              # V1
    ‚îú‚îÄ‚îÄ confusion_matrix_v2.png           # V2
    ‚îú‚îÄ‚îÄ roc_curve.png                     # V1
    ‚îú‚îÄ‚îÄ roc_curve_v2.png                  # V2
    ‚îú‚îÄ‚îÄ threshold_analysis.png            # V1
    ‚îú‚îÄ‚îÄ threshold_analysis_v2.png         # V2
    ‚îú‚îÄ‚îÄ feature_importance.png            # V1
    ‚îî‚îÄ‚îÄ feature_importance_v2.png         # V2
```

---

## üèÜ Modelos Desenvolvidos

### **V1 - Modelo Otimizado (RECOMENDADO) ‚úÖ**

**Caracter√≠sticas:**
- 50,000 amostras
- 38 features
- Remo√ß√£o de data leakage b√°sica
- Tuning de hiperpar√¢metros
- Otimiza√ß√£o de threshold (0.6)

**Performance:**
- ROC-AUC: **0.8367** ü•á
- Accuracy: **89.02%**
- Precision: **45.19%**
- Recall: **51.21%**
- F1-Score: **0.4801**

**Arquivo:** `poc.py` | `xgboost_model_optimized.json`

---

### **V2 - Modelo Enhanced (Experimental) ‚öóÔ∏è**

**Caracter√≠sticas:**
- 500,000 amostras iniciais ‚Üí 60,498 ap√≥s filtros (87.9% removido)
- 49 features (+11 novas)
- Limpeza rigorosa de dados:
  - ‚úì Usu√°rios com baixa frequ√™ncia
  - ‚úì Localiza√ß√£o inv√°lida
  - ‚úì Dist√¢ncia muito alta
  - ‚úì Paradas com poucos eventos
- Feature engineering avan√ßado
- 4 configura√ß√µes de tuning testadas

**Performance:**
- ROC-AUC: **0.7961** 
- Accuracy: **86.62%**
- Precision: **41.99%**
- Recall: **48.89%**
- F1-Score: **0.4518**

**Arquivo:** `model_v2_enhanced.py` | `xgboost_model_v2_enhanced.json`

**‚ö†Ô∏è Nota:** Performance inferior ao V1. Veja `COMPARACAO_V1_V2.md` para an√°lise detalhada.

---

## üìä Resultados Comparativos

| M√©trica | V1 (Otimizado) | V2 (Enhanced) | Vencedor |
|---------|----------------|---------------|----------|
| **ROC-AUC** | **0.8367** | 0.7961 | ‚úÖ V1 |
| **Accuracy** | **89.02%** | 86.62% | ‚úÖ V1 |
| **Precision** | **45.19%** | 41.99% | ‚úÖ V1 |
| **Recall** | **51.21%** | 48.89% | ‚úÖ V1 |
| **F1-Score** | **0.4801** | 0.4518 | ‚úÖ V1 |
| **Threshold** | 0.6 | 0.5 | - |
| **Features** | 38 | 49 | ‚úÖ V1 (mais simples) |
| **Amostras** | 50k | 60k | - |
| **Tempo Treino** | Mais r√°pido | Mais lento | ‚úÖ V1 |

**Conclus√£o:** V1 √© superior em todos os aspectos! üèÜ

---

## üöÄ Como Usar

### **1. Instalar Depend√™ncias**

```bash
conda create -n cittamobi-forecast python=3.12
conda activate cittamobi-forecast
pip install google-cloud-bigquery pandas numpy scikit-learn xgboost matplotlib seaborn
```

### **2. Autenticar com Google Cloud**

```bash
gcloud auth application-default login
```

### **3. Executar Modelo V1 (Recomendado)**

```bash
cd "/Users/stefano/Documents/Ibmec/Projeto Machine Learning"
python poc.py
```

### **4. Carregar Modelo Treinado**

```python
import xgboost as xgb
import pandas as pd

# Carregar modelo
model = xgb.Booster()
model.load_model('xgboost_model_optimized.json')

# Fazer predi√ß√µes
dmatrix = xgb.DMatrix(X_novo)
probabilidades = model.predict(dmatrix)

# Usar threshold otimizado
THRESHOLD = 0.6
predicoes = (probabilidades >= THRESHOLD).astype(int)
```

**üìñ Para instru√ß√µes detalhadas, consulte:** `GUIA_DE_USO.md`

---

## üìö Documenta√ß√£o

### **ANALISE_RESULTADOS.md**
- An√°lise completa do Modelo V1
- Compara√ß√£o Baseline vs Otimizado
- M√©tricas detalhadas
- Features mais importantes
- Recomenda√ß√µes de manuten√ß√£o

### **COMPARACAO_V1_V2.md**
- Compara√ß√£o detalhada entre V1 e V2
- An√°lise de por que V2 teve performance inferior
- Hip√≥teses e insights
- Recomenda√ß√µes para V3
- Li√ß√µes aprendidas

### **GUIA_DE_USO.md**
- Como carregar e usar o modelo
- Prepara√ß√£o de novos dados
- Interpreta√ß√£o de resultados
- Thresholds recomendados por cen√°rio
- Troubleshooting
- Monitoramento em produ√ß√£o
- Pipeline completo de predi√ß√£o

---

## üéì Principais Aprendizados

### **1. Data Leakage √© Cr√≠tico**
- Identificamos features com correla√ß√£o perfeita (1.0) com o target
- Remo√ß√£o de `y_pred`, `y_pred_proba`, e `lotacao_proxy_binaria` foi essencial
- Performance "perfeita" geralmente indica vazamento de dados

### **2. Mais Dados ‚â† Sempre Melhor**
- V1 com 50k amostras "sujas" superou V2 com 60k amostras "limpas"
- Limpeza muito rigorosa (87.9% removido) reduziu diversidade necess√°ria
- O "ru√≠do" nos dados pode conter padr√µes reais de comportamento

### **3. Feature Engineering Deve Ser Validado**
- 11 novas features em V2 n√£o melhoraram a performance
- Complexidade excessiva pode introduzir ru√≠do
- Sele√ß√£o de features √© t√£o importante quanto cria√ß√£o

### **4. Threshold Optimization √© Poderoso**
- Mudar threshold de 0.5 para 0.6 melhorou significativamente
- Precision: 30% ‚Üí 45% (+50% de melhoria!)
- Trade-off consciente entre Precision e Recall

### **5. Tuning de Hiperpar√¢metros Vale a Pena**
- ROC-AUC melhorou de 0.8214 ‚Üí 0.8367 (+1.86%)
- Encontrar configura√ß√£o ideal entre 4 testadas
- Regulariza√ß√£o (min_child_weight, gamma) ajuda muito

---

## üìà M√©tricas de Produ√ß√£o (V1)

### **Performance Esperada:**
```
ROC-AUC:   0.8367  (Excelente capacidade discriminativa)
Accuracy:  89.02%  (89 de cada 100 predi√ß√µes corretas)
Precision: 45.19%  (45% de confian√ßa em predi√ß√µes positivas)
Recall:    51.21%  (Captura 51% dos casos positivos reais)
F1-Score:  0.4801  (Bom equil√≠brio para classes desbalanceadas)
```

### **Interpreta√ß√£o de Neg√≥cio:**
- **Quando prediz Classe 1:** 45% de chance de estar correto
- **Falsos Positivos:** 1,025 casos (reduzidos em 58% vs baseline)
- **Falsos Negativos:** 805 casos
- **Uso Recomendado:** Sistemas de apoio √† decis√£o (n√£o cr√≠ticos)

---

## ‚öôÔ∏è Configura√ß√£o do Modelo V1 (Produ√ß√£o)

```python
{
    'objective': 'binary:logistic',
    'max_depth': 10,
    'learning_rate': 0.03,
    'subsample': 0.85,
    'colsample_bytree': 0.85,
    'min_child_weight': 5,
    'scale_pos_weight': 9.31,  # Para classes desbalanceadas
    'eval_metric': 'logloss',
    'seed': 42
}
```

**Threshold Otimizado:** 0.6  
**Itera√ß√µes de Treino:** 200 (com early stopping em 20)

---

## üîÑ Roadmap Futuro

### **V3 - Vers√£o H√≠brida (Planejada)**

**Objetivos:**
1. Usar `TABLESAMPLE` para amostragem aleat√≥ria (200k amostras)
2. Filtros moderados (remover 30-40%, n√£o 87.9%)
3. Selecionar top 35 features (entre V1 e V2)
4. Implementar SHAP para interpretabilidade
5. Valida√ß√£o cruzada temporal robusta
6. Ensemble de V1 + V2

**Meta:** ROC-AUC > 0.85

---

## üìû Suporte

Para d√∫vidas ou problemas:

1. **Consulte a documenta√ß√£o:**
   - `GUIA_DE_USO.md` - Uso b√°sico
   - `ANALISE_RESULTADOS.md` - M√©tricas e an√°lises
   - `COMPARACAO_V1_V2.md` - Compara√ß√µes

2. **Verifique os gr√°ficos:**
   - `confusion_matrix.png` - Erros do modelo
   - `roc_curve.png` - Capacidade discriminativa
   - `threshold_analysis.png` - Otimiza√ß√£o de threshold
   - `feature_importance.png` - Features mais importantes

3. **C√≥digo fonte:**
   - `poc.py` - Modelo V1 completo e comentado
   - `model_v2_enhanced.py` - Modelo V2 experimental

---

## üèÖ Cr√©ditos

**Projeto:** Cittamobi Forecast - Machine Learning  
**Dataset:** Google BigQuery (proj-ml-469320.app_cittamobi.dataset-updated)  
**Algoritmo:** XGBoost (Binary Classification)  
**Desenvolvido:** Outubro 2025  
**Ambiente:** Python 3.12 + Conda (cittamobi-forecast)

---

## üìÑ Licen√ßa

Este projeto √© propriet√°rio e destinado ao uso interno da Cittamobi.

---

**√öltima Atualiza√ß√£o:** 29 de Outubro de 2025  
**Vers√£o:** 2.0 (V1 Otimizado + V2 Enhanced)  
**Status:** ‚úÖ Pronto para Produ√ß√£o (V1)
