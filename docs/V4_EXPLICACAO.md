# ğŸ“š V4 ADVANCED - EXPLICAÃ‡ÃƒO DETALHADA

## ğŸ¯ Objetivo do V4

ApÃ³s anÃ¡lise dos resultados do V3 Enhanced, identificamos que:
- **Baseline simples venceu** todas as tÃ©cnicas de balanceamento
- **Precision baixa (0.43)** Ã© o principal problema
- **SMOTE prejudicou** o modelo (criou ruÃ­do)

O V4 foca em **tÃ©cnicas avanÃ§adas** sem depender de balanceamento sintÃ©tico.

---

## ğŸš€ 5 Novas EstratÃ©gias Implementadas

### 1ï¸âƒ£ **Baseline Otimizado (ReferÃªncia)**
```python
scale_pos_weight = 12.05  # RazÃ£o da classe
max_depth = 12
threshold = 0.65
```

**Como funciona:**
- Usa apenas `scale_pos_weight` do XGBoost
- Ãrvores de profundidade moderada
- Threshold otimizado para F1-Macro

**Vantagens:**
- Simples e eficaz
- Sem overfitting
- ReferÃªncia para comparaÃ§Ã£o

---

### 2ï¸âƒ£ **Cost-Sensitive Learning**
```python
scale_pos_weight = 12.05 * 1.5  # 50% mais peso
max_delta_step = 1  # Controla atualizaÃ§Ãµes
threshold = 0.60
```

**Como funciona:**
- **Aumenta o custo** de errar na classe minoritÃ¡ria
- `max_delta_step=1` limita mudanÃ§as bruscas (previne overfitting)
- Threshold mais baixo (0.60) para aumentar recall

**Quando usar:**
- Quando **falsos negativos** sÃ£o muito caros
- Quando precision pode ser sacrificada por recall

**Trade-offs:**
- âœ… **Recall aumenta** (detecta mais positivos)
- âŒ **Precision pode cair** (mais falsos positivos)

---

### 3ï¸âƒ£ **User Frequency Undersampling** (SugestÃ£o do Professor) â­
```python
# Filtrar apenas usuÃ¡rios frequentes (top 60%)
user_freq_threshold = quantile(0.40)

# Undersampling inteligente
minority = all_positive_samples
majority = top_frequent_users (ratio 5:1)
```

**Como funciona:**
1. **Filtrar usuÃ¡rios frequentes** (â‰¥ percentil 40)
   - Remove usuÃ¡rios casuais/esporÃ¡dicos
   - MantÃ©m usuÃ¡rios engajados

2. **Undersampling da classe majoritÃ¡ria**
   - MantÃ©m TODOS os positivos
   - Seleciona apenas os negativos mais relevantes
   - Prioriza usuÃ¡rios com maior `user_frequency`

3. **Ratio 5:1** (menos agressivo que 3:1)
   - 5 negativos para cada 1 positivo
   - MantÃ©m mais dados que ratio 3:1

**Por que funciona:**
- **Qualidade > Quantidade**: UsuÃ¡rios frequentes tÃªm padrÃµes mais consistentes
- **Remove ruÃ­do**: UsuÃ¡rios casuais podem ter comportamento aleatÃ³rio
- **Preserva informaÃ§Ã£o**: MantÃ©m 100% dos positivos

**Vantagens:**
- âœ… Reduz ruÃ­do do dataset
- âœ… MantÃ©m amostras de alta qualidade
- âœ… Treino mais rÃ¡pido (menos dados)
- âœ… Generaliza melhor

**Desvantagens:**
- âŒ Perde informaÃ§Ã£o de usuÃ¡rios casuais
- âŒ Pode nÃ£o funcionar se usuÃ¡rios casuais tambÃ©m convertem

---

### 4ï¸âƒ£ **Ensemble Stacking**
```python
# 3 modelos com configuraÃ§Ãµes diferentes
Model 1: Conservador  (precision â†‘, max_depth=8)
Model 2: Agressivo    (recall â†‘, max_depth=15, weight*2)
Model 3: Balanceado   (F1 â†‘, max_depth=12, weight*1.3)

# VotaÃ§Ã£o ponderada
final_prediction = mean([prob1, prob2, prob3])
```

**Como funciona:**
1. **Treina 3 modelos diferentes:**
   - **Conservador**: Alta precision, poucas prediÃ§Ãµes positivas
   - **Agressivo**: Alta recall, muitas prediÃ§Ãµes positivas
   - **Balanceado**: Meio-termo

2. **Combina probabilidades:**
   - MÃ©dia aritmÃ©tica das 3 probabilidades
   - Suaviza prediÃ§Ãµes extremas

**Por que funciona:**
- **Diversidade**: Cada modelo captura padrÃµes diferentes
- **Reduz variance**: Erros individuais se cancelam
- **Robustez**: Menos sensÃ­vel a outliers

**Vantagens:**
- âœ… Geralmente melhor que modelos individuais
- âœ… Mais robusto
- âœ… Captura diferentes aspectos dos dados

**Desvantagens:**
- âŒ 3x mais lento para treinar
- âŒ 3x mais memÃ³ria
- âŒ Mais complexo para deployment

---

### 5ï¸âƒ£ **Advanced Features + Deep Trees**
```python
max_depth = 18  # Ãrvores mais profundas
min_child_weight = 3  # Menos restriÃ§Ã£o
num_boost_round = 250  # Mais iteraÃ§Ãµes
```

**Features AvanÃ§adas Criadas:**

#### **AgregaÃ§Ãµes por UsuÃ¡rio:**
```python
user_conversion_rate    # Taxa de conversÃ£o histÃ³rica
user_total_conversions  # Total de conversÃµes
user_total_events       # FrequÃªncia total
user_avg_dist          # DistÃ¢ncia mÃ©dia
user_std_dist          # Variabilidade de distÃ¢ncia
user_min/max_dist      # Range de distÃ¢ncia
user_avg_hour          # Hora mÃ©dia de uso
user_std_hour          # Variabilidade temporal
```

**Por que ajudam:**
- Capturam **padrÃµes histÃ³ricos** do usuÃ¡rio
- UsuÃ¡rio que converte 80% das vezes â†’ alta probabilidade
- UsuÃ¡rio com distÃ¢ncia consistente â†’ comportamento previsÃ­vel

#### **AgregaÃ§Ãµes por Parada:**
```python
stop_conversion_rate      # Taxa de conversÃ£o na parada
stop_event_count_agg     # Popularidade da parada
stop_user_freq_mean      # FrequÃªncia mÃ©dia dos usuÃ¡rios
stop_user_freq_median    # FrequÃªncia mediana
```

**Por que ajudam:**
- Paradas com alta conversÃ£o â†’ mais propensas
- Paradas populares â†’ padrÃµes mais estÃ¡veis

#### **InteraÃ§Ãµes de 2Âª Ordem:**
```python
# InteraÃ§Ã£o usuÃ¡rio x parada
conversion_interaction = user_rate * stop_rate

# Desvio de comportamento
dist_deviation = |atual - mÃ©dia_usuÃ¡rio|
dist_ratio = atual / mÃ©dia_usuÃ¡rio

# Afinidade usuÃ¡rio-parada
user_stop_affinity = user_freq * stop_events
```

**Por que ajudam:**
- **Captura sinergias**: UsuÃ¡rio bom + Parada boa = excelente
- **Detecta anomalias**: DistÃ¢ncia muito diferente da mÃ©dia â†’ suspeito
- **Afinidade**: UsuÃ¡rio frequente em parada popular â†’ alta conversÃ£o

#### **Ãrvores Profundas:**
```python
max_depth = 18  # vs 12 no baseline
```

**Vantagens:**
- Captura interaÃ§Ãµes complexas entre features
- Aprende padrÃµes nÃ£o-lineares profundos

**Desvantagens:**
- âš ï¸ **Risco de overfitting** (cuidado!)
- Por isso usamos `early_stopping_rounds=25`

---

## ğŸ“Š ComparaÃ§Ã£o: Qual EstratÃ©gia Escolher?

| EstratÃ©gia | Quando Usar | Vantagem Principal |
|-----------|-------------|-------------------|
| **Baseline** | Sempre comece aqui | Simples, eficaz, rÃ¡pido |
| **Cost-Sensitive** | Falsos negativos muito caros | Aumenta recall |
| **User Freq Undersampling** | Dataset ruidoso, usuÃ¡rios casuais | Remove ruÃ­do, alta qualidade |
| **Ensemble** | ProduÃ§Ã£o, precisÃ£o crÃ­tica | Mais robusto |
| **Deep Trees + Features** | Muitos dados, relaÃ§Ãµes complexas | Captura padrÃµes complexos |

---

## ğŸ“ Conceitos Importantes

### **Precision vs Recall Trade-off**
```
Precision = VP / (VP + FP)  # Das prediÃ§Ãµes positivas, quantas corretas?
Recall = VP / (VP + FN)     # Dos reais positivos, quantos capturei?

â†‘ Precision â†’ Menos FP â†’ Menos falsos alarmes
â†‘ Recall â†’ Menos FN â†’ NÃ£o perco positivos verdadeiros
```

**V3 tinha:**
- Precision = 0.43 (de 100 prediÃ§Ãµes positivas, sÃ³ 43 eram corretas)
- Recall = 0.47 (de 100 positivos reais, detectamos 47)

### **F1-Macro vs F1-Score**
```
F1-Score = mÃ©dia harmÃ´nica entre Precision e Recall (classe 1)
F1-Macro = (F1_classe_0 + F1_classe_1) / 2

F1-Macro Ã© melhor para classes desbalanceadas!
```

**Por quÃª?**
- F1-Score ignora performance na classe majoritÃ¡ria
- F1-Macro forÃ§a o modelo a ser bom em AMBAS as classes

---

## ğŸ”¬ Experimento: O que Testar Agora?

### **PrÃ³ximos Passos:**

1. **Execute o V4:**
```bash
conda activate cittamobi-forecast
python model_v4_advanced.py
```

2. **Compare os resultados:**
- Qual estratÃ©gia teve maior F1-Macro?
- User Frequency Undersampling funcionou?
- Ensemble melhorou?

3. **Analise trade-offs:**
- Se Precision aumentou â†’ Ã“timo! Menos falsos alarmes
- Se Recall caiu muito â†’ Talvez nÃ£o vale a pena

---

## ğŸ’¡ Insights Esperados

### **User Frequency Undersampling deve:**
- âœ… **Aumentar Precision** (dados mais limpos)
- âœ… **Manter ou aumentar ROC-AUC**
- â“ **Recall pode variar** (depende da qualidade dos usuÃ¡rios frequentes)

### **Ensemble deve:**
- âœ… **Estabilizar mÃ©tricas** (menos variance)
- âœ… **Pequeno ganho em todas as mÃ©tricas**
- âœ… **ROC-AUC ligeiramente melhor**

### **Deep Trees + Features deve:**
- âœ… **Melhor performance se houver padrÃµes complexos**
- âš ï¸ **Risco de overfitting** (validar no test set!)

---

## ğŸ“ˆ CritÃ©rio de Sucesso

**V4 Ã© melhor que V3 se:**
1. **F1-Macro > 0.7143** (baseline do V3)
2. **Precision > 0.43** (problema principal)
3. **ROC-AUC â‰¥ 0.9324** (manter qualidade geral)

**Melhoria ideal:**
- Precision: 0.43 â†’ **0.50+** (16% improvement)
- F1-Macro: 0.7143 â†’ **0.73+** (2% improvement)
- Manter Recall â‰¥ 0.45

---

## ğŸ¯ ConclusÃ£o

O V4 explora tÃ©cnicas mais sofisticadas que vÃ£o alÃ©m de balanceamento simples:

1. **Custo assimÃ©trico** - penaliza erros na minoria
2. **Filtragem inteligente** - qualidade > quantidade
3. **Ensemble** - combina mÃºltiplas visÃµes
4. **Feature engineering** - captura padrÃµes complexos

**PrÃ³ximo passo:** Execute e veja qual estratÃ©gia vence! ğŸš€
